{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhyArRYMDyF7",
        "outputId": "7d87afa2-ff95-407a-a91e-c50a66d32ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, TimeDistributed, Dropout, Flatten"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nKB0D8dnDyGI",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1bWU5i0qDyGS",
        "outputId": "c3c0b5f4-88da-44ea-f508-64ea97dab885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "#read from dataset and split into input and targets\n",
        "df = pd.read_csv(\"AL_clean_2.csv\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>x1</th>\n",
              "      <th>y1</th>\n",
              "      <th>x_count</th>\n",
              "      <th>y_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>what kind of phones do you guys have</td>\n",
              "      <td>i have a it is pretty great much better than w...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>i have a it is pretty great much better than w...</td>\n",
              "      <td>does it really charge all the way in min</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>does it really charge all the way in min</td>\n",
              "      <td>pretty fast i have never it but it is under ha...</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>what kind of phones do you guys have</td>\n",
              "      <td>samsung galaxy j it is my first cell phone and...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>samsung galaxy j it is my first cell phone and...</td>\n",
              "      <td>what do you think of it anything you do not like</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... y_count\n",
              "0           0  ...       8\n",
              "1           1  ...      14\n",
              "2           2  ...       9\n",
              "3           3  ...       8\n",
              "4           4  ...      16\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZTwU8sdImkaw",
        "colab": {}
      },
      "source": [
        "# print(len(df))\n",
        "# list0 = df[\"0\"].tolist()[:num_samples]\n",
        "# list1 = df[\"1\"].tolist()[:num_samples]\n",
        "# list2 = df[\"2\"].tolist()[:num_samples]\n",
        "# print(len(list0))\n",
        "# print(len(list1))\n",
        "# print(len(list2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8s2Vd3mSGQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e1956ff3-e07a-49ee-baa3-6c653383dfd7"
      },
      "source": [
        "print(len(df))\n",
        "list0 = df[\"x1\"].tolist()[:num_samples]\n",
        "list1 = df[\"y1\"].tolist()[:num_samples]\n",
        "\n",
        "print(len(list0))\n",
        "print(len(list1))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56297\n",
            "10000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4JUwdNKQLZrw",
        "colab": {}
      },
      "source": [
        "input_texts=[]\n",
        "target_texts=[]\n",
        "#match 0 and 1\n",
        "for i in range(0,num_samples):\n",
        "    input_texts.append(str(list0[i]).split())\n",
        "    target_texts.append(['\\t'] + str(list1[i]).split() + ['\\n'])\n",
        "\n",
        "# #match 1 and 2\n",
        "# for i in range(0,num_samples):\n",
        "#     input_texts.append(list1[i].split())\n",
        "#     target_texts.append(['\\t'] + list2[i].split() + ['\\n'])\n",
        "\n",
        "# #match 0 and 2\n",
        "# for i in range(0,num_samples):\n",
        "#     input_texts.append(list0[i].split())\n",
        "#     target_texts.append(['\\t'] + list2[i].split() + ['\\n'])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GJsnuGGRZSyy",
        "colab": {}
      },
      "source": [
        "#words in input\n",
        "input_words = set()\n",
        "for sentence in (input_texts):\n",
        "    for word in sentence:\n",
        "        if word not in input_words:\n",
        "            input_words.add(word)\n",
        "            \n",
        "#words in target           \n",
        "target_words= set()\n",
        "for sentence in (target_texts):\n",
        "    for word in sentence:\n",
        "        if word not in target_words:\n",
        "            target_words.add(word)\n",
        "\n",
        "target_words.add(\"\\t\")\n",
        "target_words.add(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BdJNCnlhDyHT",
        "outputId": "8354c31d-2785-4b20-a233-071374edfd39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "input_words = sorted(list(input_words))\n",
        "target_words = sorted(list(target_words))\n",
        "\n",
        "num_encoder_tokens = len(input_words)\n",
        "num_decoder_tokens=len(target_words)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 4526\n",
            "Number of unique output tokens: 4730\n",
            "Max sequence length for inputs: 25\n",
            "Max sequence length for outputs: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Sw_fgtaDyHf",
        "colab": {}
      },
      "source": [
        "#enumerate the chars \n",
        "input_token_index = dict(\n",
        "    [(word,i) for i,word in enumerate (input_words)] )\n",
        "\n",
        "target_token_index = dict(\n",
        "    [(word,i) for i,word in enumerate (target_words)] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7B6iDWnxDyH8",
        "colab": {}
      },
      "source": [
        "# #one hot vectorization of input and target sentences - 3D array\n",
        "# encoder_input_data = np.zeros(\n",
        "#     (len(input_texts), max_encoder_seq_length, num_encoder_tokens), #number of input-ouput pairs, longest input, number of possible input words\n",
        "#     dtype='float32')\n",
        "# decoder_input_data = np.zeros(\n",
        "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens), #number of input-output pairs, longest output, number of possible output words\n",
        "#     dtype='float32')\n",
        "# decoder_target_data = np.zeros( #ahead by one time step i.e decorder_target_data @t = decoder_input_data @ t+1. #we want to predict this \n",
        "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens), \n",
        "#     dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_QdEmRCpwB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot vectorization of input and target sentences - 3D array\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length), #number of input-ouput pairs, longest input\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length), #number of input-output pairs, longest output\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros( #ahead by one time step i.e decorder_target_data @t = decoder_input_data @ t+1. #we want to predict this \n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), \n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bo95BBMvDyIJ",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)): #assign each input/output pair a number \n",
        "    for t, word in enumerate(input_text):  #assign each input sentence to a number \n",
        "        encoder_input_data[i, t] = input_token_index[word] #@pair i, word t, and where the word is located in the input_token_index\n",
        "    for t, word in enumerate(target_text): #assign each output sentence to a number \n",
        "        decoder_input_data[i, t] = target_token_index[word] #@ pair i, word t, and where the word is located in target_token_index\n",
        "        if t > 0:  #subtract one time step from input data to get target data \n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKZKaaTpDyIR",
        "colab": {}
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "dropout_rate  = 0.2\n",
        "\n",
        "#input \n",
        "encoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "#hidden layers\n",
        "encoder_embedding = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
        "encoder_dropout   = (TimeDistributed(Dropout(rate = dropout_rate)))(encoder_embedding)\n",
        "\n",
        "#output layers\n",
        "encoder_LSTM2 = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_LSTM2(encoder_dropout)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states. \n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TFXkK8ttDyIZ",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,  ))\n",
        "\n",
        "#hidden layers\n",
        "decoder_embedding = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
        "decoder_dropout = (TimeDistributed(Dropout(rate = dropout_rate)))(decoder_embedding)\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_LSTM_layer = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_LSTM,_ , _ = decoder_LSTM_layer(decoder_dropout, initial_state=encoder_states)\n",
        "\n",
        "#output\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_LSTM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQuFyR48DyIi",
        "outputId": "e02c6096-298a-4320-ec7c-2479f3ee1d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    1158656     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 256)    1210880     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, None, 256)    0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, None, 256)    0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 525312      time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  525312      time_distributed_2[0][0]         \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 4730)   1215610     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,635,770\n",
            "Trainable params: 4,635,770\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P7-9bSciDyIq",
        "outputId": "284de9c0-949a-4310-bcf9-ad2317917b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit(\n",
        "        [encoder_input_data, decoder_input_data], \n",
        "        decoder_target_data,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        # verbose=0,\n",
        "        validation_split=0.2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 63s 8ms/step - loss: 1.9856 - accuracy: 0.0440 - val_loss: 2.0176 - val_accuracy: 0.0490\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 1.8437 - accuracy: 0.0546 - val_loss: 1.9369 - val_accuracy: 0.0622\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.7600 - accuracy: 0.0625 - val_loss: 1.8975 - val_accuracy: 0.0665\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.7076 - accuracy: 0.0658 - val_loss: 1.8778 - val_accuracy: 0.0692\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.6627 - accuracy: 0.0696 - val_loss: 1.8690 - val_accuracy: 0.0701\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.6209 - accuracy: 0.0732 - val_loss: 1.8658 - val_accuracy: 0.0713\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 1.5827 - accuracy: 0.0763 - val_loss: 1.8651 - val_accuracy: 0.0721\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.5466 - accuracy: 0.0788 - val_loss: 1.8636 - val_accuracy: 0.0722\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 1.5109 - accuracy: 0.0820 - val_loss: 1.8668 - val_accuracy: 0.0726\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.4763 - accuracy: 0.0842 - val_loss: 1.8669 - val_accuracy: 0.0719\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.4434 - accuracy: 0.0871 - val_loss: 1.8734 - val_accuracy: 0.0717\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.4115 - accuracy: 0.0900 - val_loss: 1.8749 - val_accuracy: 0.0717\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.3808 - accuracy: 0.0928 - val_loss: 1.8804 - val_accuracy: 0.0706\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 1.3490 - accuracy: 0.0958 - val_loss: 1.8929 - val_accuracy: 0.0706\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.3194 - accuracy: 0.0988 - val_loss: 1.8973 - val_accuracy: 0.0710\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.2887 - accuracy: 0.1020 - val_loss: 1.9029 - val_accuracy: 0.0703\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 1.2592 - accuracy: 0.1055 - val_loss: 1.9137 - val_accuracy: 0.0689\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 1.2309 - accuracy: 0.1088 - val_loss: 1.9287 - val_accuracy: 0.0695\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.2043 - accuracy: 0.1123 - val_loss: 1.9343 - val_accuracy: 0.0670\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.1766 - accuracy: 0.1161 - val_loss: 1.9404 - val_accuracy: 0.0668\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 1.1500 - accuracy: 0.1196 - val_loss: 1.9548 - val_accuracy: 0.0670\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 1.1249 - accuracy: 0.1226 - val_loss: 1.9689 - val_accuracy: 0.0652\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.0998 - accuracy: 0.1265 - val_loss: 1.9772 - val_accuracy: 0.0652\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.0741 - accuracy: 0.1305 - val_loss: 1.9869 - val_accuracy: 0.0643\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.0509 - accuracy: 0.1343 - val_loss: 1.9980 - val_accuracy: 0.0647\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.0257 - accuracy: 0.1378 - val_loss: 2.0109 - val_accuracy: 0.0631\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 1.0022 - accuracy: 0.1415 - val_loss: 2.0249 - val_accuracy: 0.0622\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.9801 - accuracy: 0.1452 - val_loss: 2.0344 - val_accuracy: 0.0619\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.9573 - accuracy: 0.1489 - val_loss: 2.0490 - val_accuracy: 0.0623\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.9354 - accuracy: 0.1531 - val_loss: 2.0656 - val_accuracy: 0.0605\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.9132 - accuracy: 0.1561 - val_loss: 2.0732 - val_accuracy: 0.0593\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.8924 - accuracy: 0.1598 - val_loss: 2.0815 - val_accuracy: 0.0600\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.8718 - accuracy: 0.1633 - val_loss: 2.0976 - val_accuracy: 0.0587\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.8511 - accuracy: 0.1668 - val_loss: 2.1126 - val_accuracy: 0.0584\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.8315 - accuracy: 0.1707 - val_loss: 2.1211 - val_accuracy: 0.0584\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.8132 - accuracy: 0.1739 - val_loss: 2.1331 - val_accuracy: 0.0570\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.7933 - accuracy: 0.1779 - val_loss: 2.1513 - val_accuracy: 0.0563\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.7758 - accuracy: 0.1807 - val_loss: 2.1564 - val_accuracy: 0.0565\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.7589 - accuracy: 0.1836 - val_loss: 2.1679 - val_accuracy: 0.0564\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.7412 - accuracy: 0.1871 - val_loss: 2.1749 - val_accuracy: 0.0553\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.7236 - accuracy: 0.1900 - val_loss: 2.1955 - val_accuracy: 0.0557\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.7072 - accuracy: 0.1940 - val_loss: 2.2042 - val_accuracy: 0.0544\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.6914 - accuracy: 0.1971 - val_loss: 2.2152 - val_accuracy: 0.0548\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.6768 - accuracy: 0.1993 - val_loss: 2.2285 - val_accuracy: 0.0538\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.6598 - accuracy: 0.2033 - val_loss: 2.2340 - val_accuracy: 0.0540\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.6454 - accuracy: 0.2065 - val_loss: 2.2515 - val_accuracy: 0.0522\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.6309 - accuracy: 0.2095 - val_loss: 2.2610 - val_accuracy: 0.0531\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.6173 - accuracy: 0.2117 - val_loss: 2.2732 - val_accuracy: 0.0527\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.6023 - accuracy: 0.2150 - val_loss: 2.2859 - val_accuracy: 0.0520\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.5887 - accuracy: 0.2180 - val_loss: 2.3024 - val_accuracy: 0.0510\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.5758 - accuracy: 0.2210 - val_loss: 2.3130 - val_accuracy: 0.0505\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.5636 - accuracy: 0.2232 - val_loss: 2.3184 - val_accuracy: 0.0518\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.5495 - accuracy: 0.2264 - val_loss: 2.3328 - val_accuracy: 0.0512\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.5381 - accuracy: 0.2286 - val_loss: 2.3447 - val_accuracy: 0.0506\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 64s 8ms/step - loss: 0.5254 - accuracy: 0.2313 - val_loss: 2.3494 - val_accuracy: 0.0505\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.5138 - accuracy: 0.2338 - val_loss: 2.3599 - val_accuracy: 0.0510\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.5023 - accuracy: 0.2363 - val_loss: 2.3721 - val_accuracy: 0.0494\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.4917 - accuracy: 0.2383 - val_loss: 2.3837 - val_accuracy: 0.0489\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.4807 - accuracy: 0.2407 - val_loss: 2.3897 - val_accuracy: 0.0495\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.4694 - accuracy: 0.2425 - val_loss: 2.4036 - val_accuracy: 0.0493\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.4600 - accuracy: 0.2443 - val_loss: 2.4147 - val_accuracy: 0.0480\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.4492 - accuracy: 0.2476 - val_loss: 2.4197 - val_accuracy: 0.0488\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.4386 - accuracy: 0.2492 - val_loss: 2.4397 - val_accuracy: 0.0478\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.4294 - accuracy: 0.2515 - val_loss: 2.4450 - val_accuracy: 0.0487\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 66s 8ms/step - loss: 0.4195 - accuracy: 0.2531 - val_loss: 2.4526 - val_accuracy: 0.0473\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.4101 - accuracy: 0.2555 - val_loss: 2.4672 - val_accuracy: 0.0483\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.4015 - accuracy: 0.2576 - val_loss: 2.4727 - val_accuracy: 0.0474\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.3939 - accuracy: 0.2587 - val_loss: 2.4809 - val_accuracy: 0.0478\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.3857 - accuracy: 0.2607 - val_loss: 2.4860 - val_accuracy: 0.0481\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.3769 - accuracy: 0.2625 - val_loss: 2.4974 - val_accuracy: 0.0484\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.3685 - accuracy: 0.2644 - val_loss: 2.5109 - val_accuracy: 0.0478\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.3616 - accuracy: 0.2661 - val_loss: 2.5227 - val_accuracy: 0.0470\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.3526 - accuracy: 0.2678 - val_loss: 2.5270 - val_accuracy: 0.0471\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.3458 - accuracy: 0.2690 - val_loss: 2.5406 - val_accuracy: 0.0461\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.3383 - accuracy: 0.2709 - val_loss: 2.5441 - val_accuracy: 0.0473\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.3314 - accuracy: 0.2720 - val_loss: 2.5616 - val_accuracy: 0.0470\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.3258 - accuracy: 0.2730 - val_loss: 2.5628 - val_accuracy: 0.0466\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.3191 - accuracy: 0.2746 - val_loss: 2.5718 - val_accuracy: 0.0473\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.3111 - accuracy: 0.2765 - val_loss: 2.5817 - val_accuracy: 0.0467\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.3056 - accuracy: 0.2771 - val_loss: 2.5893 - val_accuracy: 0.0461\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.2992 - accuracy: 0.2787 - val_loss: 2.5956 - val_accuracy: 0.0469\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2939 - accuracy: 0.2801 - val_loss: 2.6043 - val_accuracy: 0.0466\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.2882 - accuracy: 0.2810 - val_loss: 2.6121 - val_accuracy: 0.0466\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2812 - accuracy: 0.2824 - val_loss: 2.6193 - val_accuracy: 0.0467\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 60s 8ms/step - loss: 0.2747 - accuracy: 0.2838 - val_loss: 2.6283 - val_accuracy: 0.0466\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 61s 8ms/step - loss: 0.2706 - accuracy: 0.2845 - val_loss: 2.6388 - val_accuracy: 0.0465\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2648 - accuracy: 0.2855 - val_loss: 2.6475 - val_accuracy: 0.0462\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2602 - accuracy: 0.2865 - val_loss: 2.6540 - val_accuracy: 0.0467\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.2545 - accuracy: 0.2876 - val_loss: 2.6628 - val_accuracy: 0.0467\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.2501 - accuracy: 0.2884 - val_loss: 2.6654 - val_accuracy: 0.0449\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2454 - accuracy: 0.2894 - val_loss: 2.6716 - val_accuracy: 0.0460\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2404 - accuracy: 0.2909 - val_loss: 2.6857 - val_accuracy: 0.0443\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.2356 - accuracy: 0.2915 - val_loss: 2.6926 - val_accuracy: 0.0453\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2311 - accuracy: 0.2926 - val_loss: 2.6981 - val_accuracy: 0.0447\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.2280 - accuracy: 0.2929 - val_loss: 2.7019 - val_accuracy: 0.0449\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.2215 - accuracy: 0.2945 - val_loss: 2.7162 - val_accuracy: 0.0453\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2188 - accuracy: 0.2949 - val_loss: 2.7186 - val_accuracy: 0.0449\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.2143 - accuracy: 0.2957 - val_loss: 2.7273 - val_accuracy: 0.0457\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 60s 7ms/step - loss: 0.2119 - accuracy: 0.2962 - val_loss: 2.7331 - val_accuracy: 0.0445\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 59s 7ms/step - loss: 0.2071 - accuracy: 0.2971 - val_loss: 2.7377 - val_accuracy: 0.0453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LFfFBeiEOuRR",
        "outputId": "9ea85f32-be2e-4011-8f58-7907da54f510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HqLNXzMVDyIx",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YQ2IvWkUHVos",
        "colab": {}
      },
      "source": [
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
        "decoder_dropout = (TimeDistributed(Dropout(rate = dropout_rate)))(decoder_embedding)\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_LSTM_layer(decoder_dropout, initial_state=decoder_states_inputs)\n",
        "\n",
        "# decoder_LSTM_layer = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "# decoder_LSTM,_ , _ = decoder_LSTM_layer(decoder_dropout, initial_state=encoder_states)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FR2Ti22KHYcE",
        "colab": {}
      },
      "source": [
        "# Reverse-lookup token index to decode sequences back to something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HMYQuOM1H4mX",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] =  target_token_index['\\t']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' ' + sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wx8_IAdYH5xE",
        "outputId": "0f90b69a-9dd9-4f94-e1ea-ba5e2c39f678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "for seq_index in range(11,21):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: ['fuck', 'those', 'losers', 'i', 'will', 'we', 'will', 'be', 'your', 'friend']\n",
            "Decoded sentence:  thanks \n",
            "\n",
            "-\n",
            "Input sentence: ['i', 'just', 'won', 'a', 'state', 'for', 'debate']\n",
            "Decoded sentence:  no you did not \n",
            "\n",
            "-\n",
            "Input sentence: ['no', 'you', 'did', 'not']\n",
            "Decoded sentence:  huh \n",
            "\n",
            "-\n",
            "Input sentence: ['huh']\n",
            "Decoded sentence:  heh \n",
            "\n",
            "-\n",
            "Input sentence: ['no', 'you', 'did', 'not']\n",
            "Decoded sentence:  huh \n",
            "\n",
            "-\n",
            "Input sentence: ['so', 'i', 'got', 'a', 'girlfriend', 'the', 'other', 'day']\n",
            "Decoded sentence:  that is so lovely basically\n",
            "-\n",
            "Input sentence: ['congrats', 'hope', 'you', 'are', 'as', 'happy', 'as', 'you', 'could', 'possibly', 'be']\n",
            "Decoded sentence:  oh i definitely am i still\n",
            "-\n",
            "Input sentence: ['so', 'i', 'got', 'a', 'girlfriend', 'the', 'other', 'day']\n",
            "Decoded sentence:  that is so lovely basically\n",
            "-\n",
            "Input sentence: ['that', 'is', 'so', 'lovely', 'basically', 'my', 'goals']\n",
            "Decoded sentence:  gay ass goals double here\n",
            "-\n",
            "Input sentence: ['so', 'i', 'got', 'a', 'girlfriend', 'the', 'other', 'day']\n",
            "Decoded sentence:  that is so lovely basically\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}