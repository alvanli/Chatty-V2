{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_NewModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhyArRYMDyF7",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, TimeDistributed, Dropout, Flatten, Bidirectional, Concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nKB0D8dnDyGI",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 50  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 1000  # Number of samples to train on."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1bWU5i0qDyGS",
        "outputId": "8ab13e15-0b89-4c06-c080-f529f5491e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#read from dataset and split into input and targets\n",
        "df = pd.read_csv(\"AL_clean_2.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>x1</th>\n",
              "      <th>y1</th>\n",
              "      <th>x_count</th>\n",
              "      <th>y_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>what kind of phones do you guys have</td>\n",
              "      <td>i have a it is pretty great much better than w...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>i have a it is pretty great much better than w...</td>\n",
              "      <td>does it really charge all the way in min</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>does it really charge all the way in min</td>\n",
              "      <td>pretty fast i have never it but it is under ha...</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>what kind of phones do you guys have</td>\n",
              "      <td>samsung galaxy j it is my first cell phone and...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>samsung galaxy j it is my first cell phone and...</td>\n",
              "      <td>what do you think of it anything you do not like</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... y_count\n",
              "0           0  ...       8\n",
              "1           1  ...      14\n",
              "2           2  ...       9\n",
              "3           3  ...       8\n",
              "4           4  ...      16\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZTwU8sdImkaw",
        "colab": {}
      },
      "source": [
        "# print(len(df))\n",
        "# list0 = df[\"0\"].tolist()[:num_samples]\n",
        "# list1 = df[\"1\"].tolist()[:num_samples]\n",
        "# list2 = df[\"2\"].tolist()[:num_samples]\n",
        "# print(len(list0))\n",
        "# print(len(list1))\n",
        "# print(len(list2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E8s2Vd3mSGQT",
        "outputId": "929ed0c9-faa4-4d56-da31-278da17aac78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(df))\n",
        "list0 = df[\"x1\"].tolist()[:num_samples]\n",
        "list1 = df[\"y1\"].tolist()[:num_samples]\n",
        "\n",
        "print(len(list0))\n",
        "print(len(list1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56297\n",
            "1000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4JUwdNKQLZrw",
        "colab": {}
      },
      "source": [
        "input_texts=[]\n",
        "target_texts=[]\n",
        "#match 0 and 1\n",
        "for i in range(0,num_samples):\n",
        "    input_texts.append(str(list0[i]).split())\n",
        "    target_texts.append(['\\t'] + str(list1[i]).split() + ['\\n'])\n",
        "\n",
        "# #match 1 and 2\n",
        "# for i in range(0,num_samples):\n",
        "#     input_texts.append(list1[i].split())\n",
        "#     target_texts.append(['\\t'] + list2[i].split() + ['\\n'])\n",
        "\n",
        "# #match 0 and 2\n",
        "# for i in range(0,num_samples):\n",
        "#     input_texts.append(list0[i].split())\n",
        "#     target_texts.append(['\\t'] + list2[i].split() + ['\\n'])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GJsnuGGRZSyy",
        "colab": {}
      },
      "source": [
        "#words in input\n",
        "input_words = set()\n",
        "for sentence in (input_texts):\n",
        "    for word in sentence:\n",
        "        if word not in input_words:\n",
        "            input_words.add(word)\n",
        "            \n",
        "#words in target           \n",
        "target_words= set()\n",
        "for sentence in (target_texts):\n",
        "    for word in sentence:\n",
        "        if word not in target_words:\n",
        "            target_words.add(word)\n",
        "\n",
        "target_words.add(\"\\t\")\n",
        "target_words.add(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BdJNCnlhDyHT",
        "outputId": "3011674b-fcfa-4eac-e9f1-96e2eca63ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "input_words = sorted(list(input_words))\n",
        "target_words = sorted(list(target_words))\n",
        "\n",
        "num_encoder_tokens = len(input_words)\n",
        "num_decoder_tokens=len(target_words)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 1000\n",
            "Number of unique input tokens: 1382\n",
            "Number of unique output tokens: 1539\n",
            "Max sequence length for inputs: 25\n",
            "Max sequence length for outputs: 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKGxBbfkgnJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7B6iDWnxDyH8",
        "colab": {}
      },
      "source": [
        "# #one hot vectorization of input and target sentences - 3D array\n",
        "# encoder_input_data = np.zeros(\n",
        "#     (len(input_texts), max_encoder_seq_length, num_encoder_tokens), #number of input-ouput pairs, longest input, number of possible input words\n",
        "#     dtype='float32')\n",
        "# decoder_input_data = np.zeros(\n",
        "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens), #number of input-output pairs, longest output, number of possible output words\n",
        "#     dtype='float32')\n",
        "# decoder_target_data = np.zeros( #ahead by one time step i.e decorder_target_data @t = decoder_input_data @ t+1. #we want to predict this \n",
        "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens), \n",
        "#     dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E_QdEmRCpwB7",
        "colab": {}
      },
      "source": [
        "#one hot vectorization of input and target sentences - 3D array\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length), #number of input-ouput pairs, longest input\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length), #number of input-output pairs, longest output\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros( #ahead by one time step i.e decorder_target_data @t = decoder_input_data @ t+1. #we want to predict this \n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), \n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bo95BBMvDyIJ",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)): #assign each input/output pair a number \n",
        "    for t, word in enumerate(input_text):  #assign each input sentence to a number \n",
        "        encoder_input_data[i, t] = input_token_index[word] #@pair i, word t, and where the word is located in the input_token_index\n",
        "    for t, word in enumerate(target_text): #assign each output sentence to a number \n",
        "        decoder_input_data[i, t] = target_token_index[word] #@ pair i, word t, and where the word is located in target_token_index\n",
        "        if t > 0:  #subtract one time step from input data to get target data \n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKZKaaTpDyIR",
        "colab": {}
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "dropout_rate  = 0.2\n",
        "\n",
        "#input \n",
        "encoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "#hidden layers\n",
        "encoder_embedding = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\n",
        "encoder_dropout   = (TimeDistributed(Dropout(rate = dropout_rate)))(encoder_embedding)\n",
        "\n",
        "#output layers\n",
        "encoder_LSTM = Bidirectional(LSTM(latent_dim, return_state=True, dropout=dropout_rate), merge_mode='concat')\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_LSTM(encoder_dropout)\n",
        "\n",
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate()([forward_c, backward_c])\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states. \n",
        "# encoder_states = [forward_h, forward_c, backward_h, backward_c ]\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TFXkK8ttDyIZ",
        "outputId": "137dda85-6b23-4e13-ee84-6fd4ea0aaff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,  ))\n",
        "\n",
        "#hidden layers\n",
        "decoder_embedding = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)(decoder_inputs)\n",
        "decoder_dropout = (TimeDistributed(Dropout(rate = dropout_rate)))(decoder_embedding)\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "# decoder_LSTM_layer = Bidirectional(LSTM(latent_dim, return_sequences=True, return_state=True, dropout = dropout_rate))\n",
        "# decoder_LSTM,_ , _ , _, _= decoder_LSTM_layer(decoder_dropout, initial_state=encoder_states)\n",
        "\n",
        "decoder_LSTM_layer = LSTM(latent_dim, return_sequences=True, return_state=True, dropout = dropout_rate)\n",
        "decoder_LSTM,_ , _ = decoder_LSTM_layer(decoder_dropout, initial_state=encoder_states)\n",
        "\n",
        "#output\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_LSTM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-99d380be0225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdecoder_LSTM_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdecoder_LSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_LSTM_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'constants'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'constants'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;34m'`cell.state_size`. Received `state_spec`={}; '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                     \u001b[0;34m'however `cell.state_size` is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                     '{}'.format(self.state_spec, self.cell.state_size))\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             self.state_spec = [InputSpec(shape=(None, dim))\n",
            "\u001b[0;31mValueError\u001b[0m: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=[InputSpec(shape=(None, 512), ndim=2), InputSpec(shape=(None, 512), ndim=2)]; however `cell.state_size` is (256, 256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpyZeyukCDSQ",
        "colab_type": "code",
        "outputId": "5038f5dc-9487-415b-d888-509b2211d391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.python import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQuFyR48DyIi",
        "outputId": "358d4d5a-d1c0-4218-df3d-b74afd77a575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, None, 256)    353792      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, None, 256)    393984      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, None, 256)    0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, None, 256)    0           embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) [(None, 512), (None, 1050624     time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) [(None, None, 512),  1050624     time_distributed_7[0][0]         \n",
            "                                                                 bidirectional_6[0][1]            \n",
            "                                                                 bidirectional_6[0][2]            \n",
            "                                                                 bidirectional_6[0][3]            \n",
            "                                                                 bidirectional_6[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 1539)   789507      bidirectional_7[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 3,638,531\n",
            "Trainable params: 3,638,531\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P7-9bSciDyIq",
        "outputId": "03c13599-4f63-47f6-ed1e-668ecb63e12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit(\n",
        "        [encoder_input_data, decoder_input_data], \n",
        "        decoder_target_data,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        # verbose=0,\n",
        "        validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/50\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 2.3412 - accuracy: 0.1113 - val_loss: 1.7236 - val_accuracy: 0.1346\n",
            "Epoch 2/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 2.0137 - accuracy: 0.1349 - val_loss: 1.6899 - val_accuracy: 0.1447\n",
            "Epoch 3/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.9380 - accuracy: 0.1423 - val_loss: 1.6822 - val_accuracy: 0.1491\n",
            "Epoch 4/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.8804 - accuracy: 0.1504 - val_loss: 1.6512 - val_accuracy: 0.1579\n",
            "Epoch 5/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.8071 - accuracy: 0.1732 - val_loss: 1.6577 - val_accuracy: 0.1742\n",
            "Epoch 6/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.7237 - accuracy: 0.1928 - val_loss: 1.6279 - val_accuracy: 0.1950\n",
            "Epoch 7/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.6287 - accuracy: 0.2217 - val_loss: 1.6161 - val_accuracy: 0.1969\n",
            "Epoch 8/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.5398 - accuracy: 0.2388 - val_loss: 1.5819 - val_accuracy: 0.2226\n",
            "Epoch 9/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.4483 - accuracy: 0.2703 - val_loss: 1.5715 - val_accuracy: 0.2277\n",
            "Epoch 10/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.3555 - accuracy: 0.2965 - val_loss: 1.5502 - val_accuracy: 0.2642\n",
            "Epoch 11/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.2664 - accuracy: 0.3237 - val_loss: 1.5379 - val_accuracy: 0.2761\n",
            "Epoch 12/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.1761 - accuracy: 0.3560 - val_loss: 1.5262 - val_accuracy: 0.2862\n",
            "Epoch 13/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.0927 - accuracy: 0.3852 - val_loss: 1.5176 - val_accuracy: 0.2956\n",
            "Epoch 14/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 1.0069 - accuracy: 0.4182 - val_loss: 1.4895 - val_accuracy: 0.3157\n",
            "Epoch 15/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.9272 - accuracy: 0.4478 - val_loss: 1.4714 - val_accuracy: 0.3409\n",
            "Epoch 16/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.8470 - accuracy: 0.4806 - val_loss: 1.4596 - val_accuracy: 0.3447\n",
            "Epoch 17/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.7778 - accuracy: 0.5133 - val_loss: 1.4411 - val_accuracy: 0.3572\n",
            "Epoch 18/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.7042 - accuracy: 0.5541 - val_loss: 1.4298 - val_accuracy: 0.3660\n",
            "Epoch 19/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.6371 - accuracy: 0.5956 - val_loss: 1.3955 - val_accuracy: 0.3824\n",
            "Epoch 20/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.5733 - accuracy: 0.6396 - val_loss: 1.3927 - val_accuracy: 0.3874\n",
            "Epoch 21/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.5151 - accuracy: 0.6807 - val_loss: 1.3768 - val_accuracy: 0.3937\n",
            "Epoch 22/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.4570 - accuracy: 0.7207 - val_loss: 1.3719 - val_accuracy: 0.4044\n",
            "Epoch 23/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.4050 - accuracy: 0.7540 - val_loss: 1.3481 - val_accuracy: 0.4013\n",
            "Epoch 24/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.3549 - accuracy: 0.7783 - val_loss: 1.3457 - val_accuracy: 0.4164\n",
            "Epoch 25/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.3087 - accuracy: 0.8105 - val_loss: 1.3401 - val_accuracy: 0.4170\n",
            "Epoch 26/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.2660 - accuracy: 0.8289 - val_loss: 1.3267 - val_accuracy: 0.4264\n",
            "Epoch 27/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.2295 - accuracy: 0.8490 - val_loss: 1.3261 - val_accuracy: 0.4314\n",
            "Epoch 28/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.1921 - accuracy: 0.8649 - val_loss: 1.3133 - val_accuracy: 0.4333\n",
            "Epoch 29/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.1640 - accuracy: 0.8752 - val_loss: 1.3092 - val_accuracy: 0.4352\n",
            "Epoch 30/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.1391 - accuracy: 0.8836 - val_loss: 1.2992 - val_accuracy: 0.4403\n",
            "Epoch 31/50\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.1142 - accuracy: 0.8890 - val_loss: 1.2922 - val_accuracy: 0.4491\n",
            "Epoch 32/50\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.0931 - accuracy: 0.8938 - val_loss: 1.2876 - val_accuracy: 0.4459\n",
            "Epoch 33/50\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.0781 - accuracy: 0.8949 - val_loss: 1.2882 - val_accuracy: 0.4535\n",
            "Epoch 34/50\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0624 - accuracy: 0.8969 - val_loss: 1.2815 - val_accuracy: 0.4509\n",
            "Epoch 35/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0510 - accuracy: 0.8974 - val_loss: 1.2776 - val_accuracy: 0.4509\n",
            "Epoch 36/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0421 - accuracy: 0.8977 - val_loss: 1.2732 - val_accuracy: 0.4654\n",
            "Epoch 37/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0332 - accuracy: 0.8981 - val_loss: 1.2661 - val_accuracy: 0.4610\n",
            "Epoch 38/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0277 - accuracy: 0.8978 - val_loss: 1.2635 - val_accuracy: 0.4623\n",
            "Epoch 39/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0217 - accuracy: 0.8982 - val_loss: 1.2660 - val_accuracy: 0.4660\n",
            "Epoch 40/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0174 - accuracy: 0.8982 - val_loss: 1.2632 - val_accuracy: 0.4717\n",
            "Epoch 41/50\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0146 - accuracy: 0.8981 - val_loss: 1.2654 - val_accuracy: 0.4698\n",
            "Epoch 42/50\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0116 - accuracy: 0.8982 - val_loss: 1.2553 - val_accuracy: 0.4748\n",
            "Epoch 43/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0097 - accuracy: 0.8982 - val_loss: 1.2624 - val_accuracy: 0.4742\n",
            "Epoch 44/50\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0075 - accuracy: 0.8982 - val_loss: 1.2634 - val_accuracy: 0.4792\n",
            "Epoch 45/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0064 - accuracy: 0.8982 - val_loss: 1.2548 - val_accuracy: 0.4755\n",
            "Epoch 46/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0051 - accuracy: 0.8982 - val_loss: 1.2527 - val_accuracy: 0.4780\n",
            "Epoch 47/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0042 - accuracy: 0.8982 - val_loss: 1.2534 - val_accuracy: 0.4780\n",
            "Epoch 48/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0036 - accuracy: 0.8981 - val_loss: 1.2545 - val_accuracy: 0.4836\n",
            "Epoch 49/50\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0029 - accuracy: 0.8982 - val_loss: 1.2492 - val_accuracy: 0.4887\n",
            "Epoch 50/50\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0023 - accuracy: 0.8982 - val_loss: 1.2586 - val_accuracy: 0.4887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LFfFBeiEOuRR",
        "outputId": "6dcc1b23-1c6e-4811-cc56-8b0f4b7fdcea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HqLNXzMVDyIx",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YQ2IvWkUHVos",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "454043bd-5a11-4bf0-d192-16d7806c9867"
      },
      "source": [
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_state_input_h2 = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c2 = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c, decoder_state_input_h2, decoder_state_input_c2]\n",
        "\n",
        "decoder_outputs, forward_h, forward_c, backward_h, backward_c= decoder_LSTM_layer(decoder_dropout, initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [forward_h, forward_c, backward_h, backward_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-db583bbb247f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdecoder_states_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdecoder_state_input_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_state_input_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_state_input_h2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_state_input_c2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_c\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdecoder_LSTM_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_states_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdecoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mforward_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'constants'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'constants'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    328\u001b[0m                              \u001b[0;34m'but it received '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                              \u001b[0;34m' input tensors. Input received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                              str(inputs))\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer lstm_33 expects 7 inputs, but it received 5 input tensors. Input received: [<tf.Tensor 'time_distributed_43/Reshape_1:0' shape=(None, None, 256) dtype=float32>, <tf.Tensor 'input_74:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'input_75:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'input_76:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'input_77:0' shape=(None, 256) dtype=float32>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FR2Ti22KHYcE",
        "colab": {}
      },
      "source": [
        "# Reverse-lookup token index to decode sequences back to something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HMYQuOM1H4mX",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] =  target_token_index['\\t']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        # print (decoded_sentence)\n",
        "        output_tokens, h, c, h2, c2 = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' ' + sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c, h2, c2]\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wx8_IAdYH5xE",
        "outputId": "ff092ab4-a2a8-40fd-cb8b-417218cf7af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for seq_index in range(10):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['what', 'kind', 'of', 'phones', 'do', 'you', 'guys', 'have']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['i', 'have', 'a', 'it', 'is', 'pretty', 'great', 'much', 'better', 'than', 'what', 'i', 'had', 'before']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['does', 'it', 'really', 'charge', 'all', 'the', 'way', 'in', 'min']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['what', 'kind', 'of', 'phones', 'do', 'you', 'guys', 'have']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['samsung', 'galaxy', 'j', 'it', 'is', 'my', 'first', 'cell', 'phone', 'and', 'i', 'have', 'had', 'it', 'for', 'months']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['what', 'do', 'you', 'think', 'of', 'it', 'anything', 'you', 'do', 'not', 'like']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['what', 'kind', 'of', 'phones', 'do', 'you', 'guys', 'have']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['optimums', 'v', 'i', 'know', 'it', 'is', 'old']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['my', 'friend', 'told', 'me', 'to', 'kill', 'myself']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "-\n",
            "Input sentence: ['do', 'not', 'kill', 'yourself', 'op']\n",
            "Decoded sentence:  \t \t \t \t \t \t \t \t \t \t \t \t \t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}