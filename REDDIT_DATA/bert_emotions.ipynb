{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b7b09f4288>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "root_dir = \"C://DATA//train//21_doggy\"\n",
    "df = pd.read_csv(os.path.join(root_dir, \"DATA//emotion.data\"))\n",
    "df = df.drop(\"Unnamed: 0\",axis= 1)\n",
    "df.head()\n",
    "df.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b7c178d108>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"emotions\"][df[\"emotions\"] == \"joy\"] = 1\n",
    "df[\"emotions\"][df[\"emotions\"] == \"love\"] = 1\n",
    "df[\"emotions\"][df[\"emotions\"] == \"sadness\"] = 0\n",
    "df[\"emotions\"][df[\"emotions\"] == \"anger\"] = 0\n",
    "df[\"emotions\"][df[\"emotions\"] == \"fear\"] = 0\n",
    "df = df[df[\"emotions\"] != \"surprise\"]\n",
    "df.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions\n",
       "0  i feel awful about it too because it s my job ...        0\n",
       "1                              im alone i feel awful        0\n",
       "2  ive probably mentioned this before but i reall...        1\n",
       "3           i was feeling a little low few days back        0\n",
       "4  i beleive that i am much more sensitive to oth...        1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241102\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac = 1)\n",
    "df_train = df.iloc[:int(len(df)*.6)]\n",
    "df_test = df.iloc[int(len(df)*.8):int(len(df)*.9)]\n",
    "df_val = df.iloc[int(len(df)*.9):]\n",
    "df_train.to_csv(os.path.join(root_dir, \"train.csv\"), index = False) \n",
    "df_test.to_csv(os.path.join(root_dir, \"test.csv\"), index = False)\n",
    "df_val.to_csv(os.path.join(root_dir, \"valid.csv\"), index = False)\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22939</td>\n",
       "      <td>i start to feel like sending a thank you now w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165085</td>\n",
       "      <td>i have been thinking about stories about tight...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53698</td>\n",
       "      <td>i was feeling shaken by the first</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123854</td>\n",
       "      <td>i feel like talking typing and joe purdy just ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58039</td>\n",
       "      <td>i feel very honoured i feel very privileged bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text emotions\n",
       "22939   i start to feel like sending a thank you now w...        0\n",
       "165085  i have been thinking about stories about tight...        1\n",
       "53698                   i was feeling shaken by the first        0\n",
       "123854  i feel like talking typing and joe purdy just ...        1\n",
       "58039   i feel very honoured i feel very privileged bu...        1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'neg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-776c53a7a8a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memotions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'neg'"
     ]
    }
   ],
   "source": [
    "dis = df.emotions.value_counts()\n",
    "dis.neg / (dis.neg + dis.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator, Dataset, Example\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Model parameter\n",
    "MAX_SEQ_LEN = 128\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "\n",
    "# TabularDataset\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "fields = [('text', text_field),('label', label_field)]\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=root_dir, train='train.csv', validation='valid.csv',\n",
    "                                           test='test.csv', format='csv', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "test_iter = Iterator(test, batch_size=16, device=device, train=False, shuffle=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = \"bert-base-uncased\"\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
    "\n",
    "    def forward(self, text, label):\n",
    "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):\n",
    "    \n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-794912c5d86d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-82-794912c5d86d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, train_loader, valid_loader, num_epochs, eval_every, file_path, best_valid_loss)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-71a85d6c1fce>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text, label)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_fea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_fea\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states)\u001b[0m\n\u001b[0;32m   1265\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1268\u001b[0m         )\n\u001b[0;32m   1269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m         )\n\u001b[0;32m    764\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m                 )\n\u001b[0;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add cross attentions if we output attention weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1611\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1612\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "destination_folder = root_dir\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (text, labels), _ in train_loader:\n",
    "            labels = labels.type(torch.LongTensor)           \n",
    "            labels = labels.to(device)\n",
    "            text = text.type(torch.LongTensor)  \n",
    "            text = text.to(device)\n",
    "            output = model(text, labels)\n",
    "            loss, _ = output\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "\n",
    "                    # validation loop\n",
    "                    for (text, labels), _ in valid_loader:\n",
    "                        labels = labels.type(torch.LongTensor)           \n",
    "                        labels = labels.to(device)\n",
    "                        text = text.type(torch.LongTensor)  \n",
    "                        text = text.to(device)\n",
    "                        output = model(text, labels)\n",
    "                        loss, _ = output\n",
    "                        \n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n",
    "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "model = BERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "train(model=model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (labels, title, text, titletext), _ in test_loader:\n",
    "\n",
    "                labels = labels.type(torch.LongTensor)           \n",
    "                labels = labels.to(device)\n",
    "                titletext = titletext.type(torch.LongTensor)  \n",
    "                titletext = titletext.to(device)\n",
    "                output = model(titletext, labels)\n",
    "\n",
    "                _, output = output\n",
    "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "                y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    \n",
    "best_model = BERT().to(device)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model)\n",
    "\n",
    "evaluate(best_model, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
