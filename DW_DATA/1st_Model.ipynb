{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1st_Model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrF-_9eHxNGh",
        "colab_type": "code",
        "outputId": "1dd90421-fa42-4fb4-d808-4b644d8dae8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd ..\n",
        "%cd root\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbJM72pxg1O",
        "colab_type": "code",
        "outputId": "3ed3eee0-8e9d-4baa-8721-56b63234bcd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"dwdata_1.csv\")\n",
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>im pleased you two are so impressed i find the...</td>\n",
              "      <td>yes i suppose the atmosphere is rather rancid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hes let us go</td>\n",
              "      <td>he needs to move his tardis into the circle of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>without special treatment it would have spread...</td>\n",
              "      <td>ah thats nice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>when i came back with these satellite reports ...</td>\n",
              "      <td>nothings been moved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>there it is but he could be anywhere</td>\n",
              "      <td>fair exchange is no robbery the masters tempor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                  Y\n",
              "0           0  ...      yes i suppose the atmosphere is rather rancid\n",
              "1           1  ...  he needs to move his tardis into the circle of...\n",
              "2           2  ...                                      ah thats nice\n",
              "3           3  ...                                nothings been moved\n",
              "4           4  ...  fair exchange is no robbery the masters tempor...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGnNmu5Vx6t6",
        "colab_type": "text"
      },
      "source": [
        "Punctuation has already been removed, all words are lowered. I suppose stemming would not be a nice idea unless we preprocess the data whenever a user enters something. Let's build a simple model then!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38My9GYry_WY",
        "colab_type": "code",
        "outputId": "940abd18-708a-4766-dc74-87f3f06e68c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import numpy as np\n",
        "words_x = [\"\"]\n",
        "words_y = [\"\"]\n",
        "def word_to_list_x(x):\n",
        "  words_x.append(str(x).split(\" \"))\n",
        "def word_to_list_y(x):\n",
        "  words_y.append(str(x).split(\" \"))\n",
        "df.X.apply(word_to_list_x)\n",
        "df.Y.apply(word_to_list_y)\n",
        "words_x1 = [val for sublist in words_x for val in sublist]\n",
        "words_y1 = [val for sublist in words_y for val in sublist]\n",
        "words_x = set(words_x1)\n",
        "words_y = set(words_y1)\n",
        "print(\"X:\")\n",
        "print(\"   # of unique words: {}, Total Words: {}\".format(len(words_x), len(words_x1)))\n",
        "print(\"Y: \")\n",
        "print(\"   # of unique words: {}, Total Words: {}\".format(len(words_y), len(words_y1)))\n",
        "print(\"Combined: \")\n",
        "print(\"   # of unique words: {}, Total Words: {}\".format(len(set(list(words_y)+list(words_x))), len(words_y1+words_x1)))\n",
        "print(\"Total Training Size: {}\".format(len(df)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:\n",
            "   # of unique words: 30793, Total Words: 725045\n",
            "Y: \n",
            "   # of unique words: 37657, Total Words: 939351\n",
            "Combined: \n",
            "   # of unique words: 53382, Total Words: 1664396\n",
            "Total Training Size: 76543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvKQJeUA1UiK",
        "colab_type": "code",
        "outputId": "2787c648-e58d-42ef-ca80-2ddcb754c8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "pd.Series(words_y1+words_x1).value_counts()[20:30].plot.bar()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f672b1889e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOY0X-IS4h1L",
        "colab_type": "text"
      },
      "source": [
        "Max words per sentence is 253 as per the last notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgXzxnPh5Rw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "def remove_num_X(x):\n",
        "  x = str(x)\n",
        "  result = ''.join([i for i in x if not i.isdigit()])\n",
        "  X.append(result)\n",
        "def remove_num_Y(x):\n",
        "  x = str(x)\n",
        "  result = ''.join([i for i in x if not i.isdigit()])\n",
        "  Y.append(result)\n",
        "df.X.apply(remove_num_X)\n",
        "df.Y.apply(remove_num_Y)\n",
        "df[\"X_1\"] = X\n",
        "df[\"Y_1\"] = Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFYXMy0U7gEC",
        "colab_type": "code",
        "outputId": "2d283c37-4e63-420b-fc14-f49ebaec99e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "word_freq = pd.Series(words_y1+words_x1).value_counts()\n",
        "print(\"Total Number of Unique Words Before: {}\".format(len(word_freq)))\n",
        "ignored = word_freq[word_freq<=4]\n",
        "word_freq = word_freq[word_freq>4]\n",
        "print(\"Total Number of Unique Words After: {}\".format(len(word_freq)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Unique Words Before: 53382\n",
            "Total Number of Unique Words After: 11699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwYpPQFn7HMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ignored = list(ignored)\n",
        "X_1 = []\n",
        "Y_1 = []\n",
        "def filter_ignored_x(x):\n",
        "  each_word = x.split(\" \")\n",
        "  result = \" \".join([i for i in each_word if i not in ignored])\n",
        "  X_1.append(result)\n",
        "def filter_ignored_y(x):\n",
        "  each_word = x.split(\" \")\n",
        "  result = \" \".join([i for i in each_word if i not in ignored])\n",
        "  Y_1.append(result)\n",
        "df[\"X_1\"].apply(filter_ignored_x)\n",
        "df[\"Y_1\"].apply(filter_ignored_y)\n",
        "df[\"X_1\"] = X_1\n",
        "df[\"Y_1\"] = Y_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDnQfjxK6DTV",
        "colab_type": "code",
        "outputId": "c1cc0205-96b5-4dd7-a7d7-234dff236a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>X_1</th>\n",
              "      <th>Y_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>im pleased you two are so impressed i find the...</td>\n",
              "      <td>yes i suppose the atmosphere is rather rancid</td>\n",
              "      <td>im pleased you two are so impressed i find the...</td>\n",
              "      <td>yes i suppose the atmosphere is rather rancid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hes let us go</td>\n",
              "      <td>he needs to move his tardis into the circle of...</td>\n",
              "      <td>hes let us go</td>\n",
              "      <td>he needs to move his tardis into the circle of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>without special treatment it would have spread...</td>\n",
              "      <td>ah thats nice</td>\n",
              "      <td>without special treatment it would have spread...</td>\n",
              "      <td>ah thats nice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>when i came back with these satellite reports ...</td>\n",
              "      <td>nothings been moved</td>\n",
              "      <td>when i came back with these satellite reports ...</td>\n",
              "      <td>nothings been moved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>there it is but he could be anywhere</td>\n",
              "      <td>fair exchange is no robbery the masters tempor...</td>\n",
              "      <td>there it is but he could be anywhere</td>\n",
              "      <td>fair exchange is no robbery the masters tempor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                Y_1\n",
              "0           0  ...      yes i suppose the atmosphere is rather rancid\n",
              "1           1  ...  he needs to move his tardis into the circle of...\n",
              "2           2  ...                                      ah thats nice\n",
              "3           3  ...                                nothings been moved\n",
              "4           4  ...  fair exchange is no robbery the masters tempor...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfXv1AqrFmKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3w8VNTxx5jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 255\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "all_xy = df[\"X_1\"]\n",
        "all_xy = all_xy.append(df[\"Y_1\"])\n",
        "TO = Tokenizer(num_words=20000)\n",
        "TO.fit_on_texts(all_xy)\n",
        "X_train = TO.texts_to_sequences(df[\"X_1\"])\n",
        "Y_train = TO.texts_to_sequences(df[\"Y_1\"])\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "Y_train = pad_sequences(Y_train, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZButX2m06zDu",
        "colab_type": "code",
        "outputId": "31527c46-3ea1-4a55-a213-57b6676d4419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76543, 255)\n",
            "(76543, 255)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neAQs2mwFV86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def glove_100d_dictionary(GLOVE_DIR):\n",
        "  embeddings_index = {}\n",
        "  f = open(os.path.join(GLOVE_DIR, 'glove.42B.300d.txt'))\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "  f.close()\n",
        "  return embeddings_index\n",
        "def embedding_matrix_creater(embedding_dimention):\n",
        "  embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimention))\n",
        "  for word, i in word_index.items():\n",
        "      embedding_vector = embeddings_index.get(word)\n",
        "      if embedding_vector is not None:\n",
        "          # words not found in embedding index will be all-zeros.\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "  return embedding_matrix\n",
        "def embedding_layer_creater(VOCAB_SIZE, EMBEDDING_DIM, MAX_LEN, embedding_matrix):\n",
        "  \n",
        "  embedding_layer = Embedding(input_dim = VOCAB_SIZE, \n",
        "                              output_dim = EMBEDDING_DIM,\n",
        "                              input_length = MAX_LEN,\n",
        "                              weights = [embedding_matrix],\n",
        "                              trainable = False)\n",
        "  return embedding_layer\n",
        "\n",
        "embedding_layer = embedding_layer_creater(VOCAB_SIZE, EMBEDDING_DIM, MAX_LEN, embedding_matrix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DejbaJuuDto4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Input, Add, Dense, Flatten, Bidirectional, GlobalMaxPool1D, Dropout\n",
        "#https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639\n",
        "encoder_inputs = Input(shape=(maxlen, ), dtype='int32',)\n",
        "encoder_embedding = embed_layer(encoder_inputs)\n",
        "encoder_LSTM = LSTM(128, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
        "\n",
        "decoder_inputs = Input(shape=(maxlen, ), dtype='int32',)\n",
        "decoder_embedding = embed_layer(decoder_inputs)\n",
        "decoder_LSTM = LSTM(128, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "outputs = TimeDistributed(Dense(20000, activation='softmax'))(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}