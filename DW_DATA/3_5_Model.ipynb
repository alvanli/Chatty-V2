{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_5_Model",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqge7r5GOxX",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, I will mainly add embeddings. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGqN2bd-GGK0",
        "colab_type": "code",
        "outputId": "de149ec7-6e6a-439a-afbe-60cad6164ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "%cd ..\n",
        "%cd root\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"dwdata_3.csv\")\n",
        "df.head()\n",
        "df.fillna('', inplace=True)\n",
        "print(len(df))\n",
        "x_1 = df[\"xx\"].tolist()\n",
        "y_1 = df[\"yy\"].tolist()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/root\n",
            "76543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3X_nPPcBSMY",
        "colab_type": "code",
        "outputId": "f7156e00-3d7d-4a64-ca9a-4a99f0a26b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word2vec_index = {}\n",
        "f = open(\"glove.6B.100d.txt\",encoding=\"utf8\")\n",
        "for line in f:\n",
        "    words = line.split()\n",
        "    word = words[0]\n",
        "    index = np.asarray(words[1:], dtype=\"float32\")\n",
        "    word2vec_index[word] = index\n",
        "f.close()\n",
        "\n",
        "print(\"The number of word vectors are: \", len(word2vec_index))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of word vectors are:  400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJE_MBJCq63o",
        "colab_type": "code",
        "outputId": "ab3f8621-91bb-4334-ebca-5873bbfc57d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "token = tfds.features.text.SubwordTextEncoder.build_from_corpus(x_1+y_1, target_vocab_size=1e12)\n",
        "\n",
        "vocab_size = token.vocab_size + 2 # adding the start and end characters\n",
        "\n",
        "inputs = [token.encode(sentence) for sentence in x_1]\n",
        "outputs = [[vocab_size - 2] + token.encode(sentence) + [vocab_size - 1] for sentence in y_1]\n",
        "print(\"{},{}\".format(len(inputs),len(outputs)))\n",
        "df[\"sent_len\"] = [len(sent) for sent in inputs]\n",
        "MAXLEN = 50\n",
        "idx_to_shorten = [count for count, sent in enumerate(inputs) if len(sent) > MAXLEN]\n",
        "for idx in idx_to_shorten:\n",
        "    inputs[idx] = inputs[idx][:MAXLEN]\n",
        "    outputs[idx] = outputs[idx][:MAXLEN]\n",
        "idx_to_shorten = []\n",
        "idx_to_shorten = [count for count, sent in enumerate(outputs) if len(sent) > MAXLEN]\n",
        "for idx in idx_to_shorten:\n",
        "    inputs[idx] = inputs[idx][:MAXLEN]\n",
        "    outputs[idx] = outputs[idx][:MAXLEN]\n",
        "# deleted min len because short convos are still good :)\n",
        "inputs = pad_sequences(inputs, value=0, padding=\"post\", maxlen=MAXLEN)\n",
        "outputs = pad_sequences(outputs, value=0, padding=\"post\", maxlen=MAXLEN)\n",
        "print(\"{},{}\".format(inputs.shape,outputs.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76543,76543\n",
            "(76543, 50),(76543, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm0hU620H-dE",
        "colab_type": "code",
        "outputId": "0facf905-266d-4696-ef00-17882b2ee147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>X_1</th>\n",
              "      <th>Y_1</th>\n",
              "      <th>xx</th>\n",
              "      <th>yy</th>\n",
              "      <th>sent_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>im pleased you two are so impressed i find the...</td>\n",
              "      <td>yes i suppose the atmosphere is rather rancid</td>\n",
              "      <td>im pleased you two are so impressed i find the...</td>\n",
              "      <td>yes i suppose the atmosphere is rather rancid</td>\n",
              "      <td>im pleased you two are so impressed i find the...</td>\n",
              "      <td>yes i suppose the atmosphere is rather</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hes let us go</td>\n",
              "      <td>he needs to move his tardis into the circle of...</td>\n",
              "      <td>hes let us go</td>\n",
              "      <td>he needs to move his tardis into the circle of...</td>\n",
              "      <td>he is let us go</td>\n",
              "      <td>he needs to move his tardis into the circle of...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>without special treatment it would have spread...</td>\n",
              "      <td>ah thats nice</td>\n",
              "      <td>without special treatment it would have spread...</td>\n",
              "      <td>ah thats nice</td>\n",
              "      <td>without special treatment it would have spread...</td>\n",
              "      <td>ah thats nice</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>when i came back with these satellite reports ...</td>\n",
              "      <td>nothings been moved</td>\n",
              "      <td>when i came back with these satellite reports ...</td>\n",
              "      <td>nothings been moved</td>\n",
              "      <td>when i came back with the ise satellite report...</td>\n",
              "      <td>nothings been moved</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>there it is but he could be anywhere</td>\n",
              "      <td>fair exchange is no robbery the masters tempor...</td>\n",
              "      <td>there it is but he could be anywhere</td>\n",
              "      <td>fair exchange is no robbery the masters tempor...</td>\n",
              "      <td>there it is but he could be anywhere</td>\n",
              "      <td>fair exchange is no robbery the masters tempor...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... sent_len\n",
              "0           0  ...       11\n",
              "1           1  ...        5\n",
              "2           2  ...       11\n",
              "3           3  ...       19\n",
              "4           4  ...        8\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6e82tsSq8FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "for sentence in (x_1 + y_1):\n",
        "    words = sentence.split(\" \")\n",
        "    for word in words:\n",
        "        if word not in vocab:\n",
        "            vocab.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glBunzFnrAVD",
        "colab_type": "code",
        "outputId": "2f08f51e-5242-4dc2-a3f3-f709248a8c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "count = 0\n",
        "count_1 = 0\n",
        "not_glove = []\n",
        "for i, word in enumerate(token.subwords):\n",
        "    if (word[-1] == \"_\"):\n",
        "        word = word[:-1]\n",
        "    embedding_vector = word2vec_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # we found the word - add that words vector to the matrix\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        count_1 += 1\n",
        "    else:\n",
        "        # doesn't exist, assign a random vector\n",
        "        embedding_matrix[i] = np.random.randn(100)\n",
        "        not_glove.append(word)\n",
        "        count += 1\n",
        "print(\"In GLOVE: {}, Not in GLOVE: {}\".format(count_1, count))\n",
        "# HALF OF THE WORDS ARE NOT IN GLOVE WHYYYYYYYYYYY (glove.6B.100d)\n",
        "# The updated version has 92% of the vocab in glove! Yay!"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In GLOVE: 11558, Not in GLOVE: 703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbQo0e7vrVvE",
        "colab_type": "code",
        "outputId": "60710b12-a30f-4803-a2d5-5cfb70479495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from scipy.ndimage.interpolation import shift\n",
        "inputs_1 = inputs\n",
        "inputs_2 = outputs\n",
        "outputs_1 = outputs\n",
        "outputs_1 = shift(outputs_1, [0,-1], cval=0)\n",
        "print(\"{},{}\".format(inputs_1.shape,outputs_1.shape))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76543, 50),(76543, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj6dJIVuNu8F",
        "colab_type": "code",
        "outputId": "89b2035c-bed2-43de-be6a-4ea221ab8791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVeWwGFgN2Jh",
        "colab_type": "code",
        "outputId": "37831c0c-4474-4a87-c301-85fbe1174aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# from tqdm import tqdm\n",
        "# x1 = []\n",
        "# x2 = []\n",
        "# y1 = []\n",
        "# for sentence in tqdm(inputs_1):\n",
        "#   sentence1 = []\n",
        "#   for index in sentence:\n",
        "#     onehot = np.zeros((vocab_size))\n",
        "#     onehot[index] = 1\n",
        "#     sentence1.append(onehot)\n",
        "#   x1.append(sentence1)\n",
        "# for sentence in tqdm(inputs_2):\n",
        "#   sentence1 = []\n",
        "#   for index in sentence:\n",
        "#     onehot = np.zeros((vocab_size))\n",
        "#     onehot[index] = 1\n",
        "#     sentence1.append(onehot)\n",
        "#   x2.append(sentence1)\n",
        "# for sentence in tqdm(outputs_1):\n",
        "#   sentence1 = []\n",
        "#   for index in sentence:\n",
        "#     onehot = np.zeros((vocab_size))\n",
        "#     onehot[index] = 1\n",
        "#     sentence1.append(onehot)\n",
        "#   y1.append(sentence1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  6%|â–‹         | 4929/76543 [00:13<04:18, 276.60it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MjpK66GrfpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, Dropout, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.models import Model\n",
        "# latent_dim = 256\n",
        "# Shared_Embedding = Embedding(vocab_size,100,weights=[embedding_matrix],input_length=MAXLEN,trainable=True)\n",
        "\n",
        "# encoder_inputs = Input(shape=(MAXLEN), dtype='int32')\n",
        "# encoder_embedding = Shared_Embedding(encoder_inputs)\n",
        "# encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state = True)(encoder_embedding)\n",
        "\n",
        "# decoder_inputs = Input(shape=(MAXLEN), dtype='int32')\n",
        "# decoder_embedding = Shared_Embedding(decoder_inputs)\n",
        "# decoder_outputs, _, _ = LSTM(latent_dim, return_state=True, return_sequences=True)(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "# outputs_model = Dense(1, activation='softmax')(decoder_outputs)\n",
        "# model = Model([encoder_inputs, decoder_inputs], outputs_model)\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=2), metrics=['accuracy'])\n",
        "\n",
        "latent_dim = 256\n",
        "encoder_inputs = Input(shape=(MAXLEN,1))\n",
        "lstm = LSTM(latent_dim, return_state = True)\n",
        "encoder_outputs, state_h, state_c = lstm(encoder_inputs)\n",
        "\n",
        "decoder_inputs = Input(shape=(MAXLEN,1))\n",
        "lstm1 = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _, _ = lstm1(decoder_inputs, initial_state=[state_h, state_c])\n",
        "\n",
        "outputs_model = Dense(1, activation='softmax')(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs_model)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.05))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-tcJb1Zri46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = 10\n",
        "hist = model.fit([inputs_1[:sub], inputs_2[:sub]], outputs_1[:sub],batch_size=32,epochs=50,validation_split=0.2, verbose = 0)\n",
        "model.save(\"3rd_m.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CupUf71Gsmhd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "12c9a8a2-5f4c-4394-9d66-56b3bcf40971"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history[\"loss\"],color=\"r\")\n",
        "plt.plot(hist.history[\"val_loss\"],color=\"b\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0db6ce5e10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwBMGVqgtq2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use bidirectional lstm next time?\n",
        "#https://github.com/oswaldoludwig/Adversarial-Learning-for-Generative-Conversational-Agents !!!!GAANNN!!!!\n",
        "# Put attention in as well!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQKFPRC5olTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0f945fe4-eaec-419b-a0ba-c3052a485548"
      },
      "source": [
        "print(inputs_2[1][0])\n",
        "print(inputs_2[2][0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12518\n",
            "12518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hQCUjwytzPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "b09a935e-c12d-4b7f-d48c-b9d74c12b216"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # input_seq = np.expand_dims(input_seq,axis=-1)\n",
        "    partial = np.zeros((1,MAXLEN))\n",
        "    partial[0,0] = vocab_size-2\n",
        "    decoded_sentence = []\n",
        "    for _ in range(MAXLEN-1):\n",
        "        pred = model.predict([input_seq, partial])\n",
        "        partial[0,:] = pred[0,:,0]\n",
        "    # pred = token.decode([int(i) for i in decoded_sentence])\n",
        "    return partial[0]\n",
        "index_try = 33\n",
        "input_seq = inputs_1[index_try: index_try + 1]\n",
        "pred = decode_sequence(input_seq)\n",
        "print('-')\n",
        "print('Input sentence:', token.decode(inputs_1[index_try]))\n",
        "print('Decoded sentence:', pred)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: keep your eyes he cant have got far\n",
            "Decoded sentence: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}