{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3rd_Model","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOSmhzF/Vaivx1bPkNWA0T6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FIqge7r5GOxX","colab_type":"text"},"source":["In this notebook, I will mainly add embeddings. <br>\n","Note: Suspect something wrong with output layer, also, dont think I used embedding properly, will be redoing this notebook!"]},{"cell_type":"code","metadata":{"id":"rGqN2bd-GGK0","colab_type":"code","outputId":"02a61dec-5976-48d5-8743-5b2a9b87ba3e","executionInfo":{"status":"ok","timestamp":1587304138523,"user_tz":240,"elapsed":1521,"user":{"displayName":"Alvin Li","photoUrl":"","userId":"06437038450383299514"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["%cd ..\n","%cd root\n","import numpy as np\n","import pandas as pd\n","df = pd.read_csv(\"dwdata_2.csv\")\n","df.head()\n","df.fillna('', inplace=True)\n","print(len(df))\n","x_1 = df[\"X_1\"].tolist()\n","y_1 = df[\"Y_1\"].tolist()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/\n","/root\n","76543\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_3X_nPPcBSMY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8f46a236-4271-4f6a-9c51-6662ccaf2dc5","executionInfo":{"status":"ok","timestamp":1587303960900,"user_tz":240,"elapsed":3381,"user":{"displayName":"Alvin Li","photoUrl":"","userId":"06437038450383299514"}}},"source":["word2vec_index = {}\n","f = open(\"glove.6B.100d.txt\",encoding=\"utf8\")\n","for line in f:\n","    words = line.split()\n","    word = words[0]\n","    index = np.asarray(words[1:], dtype=\"float32\")\n","    word2vec_index[word] = index\n","f.close()\n","\n","print(\"The number of word vectors are: \", len(word2vec_index))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["The number of word vectors are:  95172\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jJE_MBJCq63o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"1cd667fd-02d6-4d24-ae93-34703a6a694a","executionInfo":{"status":"ok","timestamp":1587304230177,"user_tz":240,"elapsed":86053,"user":{"displayName":"Alvin Li","photoUrl":"","userId":"06437038450383299514"}}},"source":["import tensorflow_datasets as tfds\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","token = tfds.features.text.SubwordTextEncoder.build_from_corpus(x_1+y_1, target_vocab_size=1e12)\n","# token_y = tfds.features.text.SubwordTextEncoder.build_from_corpus(y_1, target_vocab_size=1e12)\n","\n","vocab_size = token.vocab_size + 2 # adding the start and end characters\n","\n","inputs = [token.encode(sentence) for sentence in x_1]\n","outputs = [[vocab_size - 2] + token.encode(sentence) + [vocab_size - 1] for sentence in y_1]\n","print(\"{},{}\".format(len(inputs),len(outputs)))\n","MAXLEN = 70\n","idx_to_shorten = [count for count, sent in enumerate(inputs) if len(sent) > MAXLEN]\n","for idx in idx_to_shorten:\n","    inputs[idx] = inputs[idx][:MAXLEN]\n","    outputs[idx] = outputs[idx][:MAXLEN]\n","idx_to_shorten = []\n","idx_to_shorten = [count for count, sent in enumerate(outputs) if len(sent) > MAXLEN]\n","for idx in idx_to_shorten:\n","    inputs[idx] = inputs[idx][:MAXLEN]\n","    outputs[idx] = outputs[idx][:MAXLEN]\n","# deleted min len because short convos are still good :)\n","inputs = pad_sequences(inputs, value=0, padding=\"post\", maxlen=MAXLEN)\n","outputs = pad_sequences(outputs, value=0, padding=\"post\", maxlen=MAXLEN)\n","print(\"{},{}\".format(inputs.shape,outputs.shape))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["76543,76543\n","(76543, 70),(76543, 70)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u6e82tsSq8FY","colab_type":"code","colab":{}},"source":["vocab = set()\n","for sentence in (x_1 + y_1):\n","    words = sentence.split(\" \")\n","    for word in words:\n","        if word not in vocab:\n","            vocab.add(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"glBunzFnrAVD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"9a90423c-330e-466b-fc1b-8823cac51d77","executionInfo":{"status":"ok","timestamp":1587304304422,"user_tz":240,"elapsed":1017,"user":{"displayName":"Alvin Li","photoUrl":"","userId":"06437038450383299514"}}},"source":["embedding_matrix = np.zeros((vocab_size, 100))\n","count = 0\n","count_1 = 0\n","not_glove = []\n","for i, word in enumerate(token.subwords):\n","    if (word[-1] == \"_\"):\n","        word = word[:-1]\n","    embedding_vector = word2vec_index.get(word)\n","    if embedding_vector is not None:\n","        # we found the word - add that words vector to the matrix\n","        embedding_matrix[i] = embedding_vector\n","        count_1 += 1\n","    else:\n","        # doesn't exist, assign a random vector\n","        embedding_matrix[i] = np.random.randn(100)\n","        not_glove.append(word)\n","        count += 1\n","print(\"In GLOVE: {}, Not in GLOVE: {}\".format(count_1, count))\n","# HALF OF THE WORDS ARE NOT IN GLOVE WHYYYYYYYYYYY (glove.6B.100d)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["In GLOVE: 27940, Not in GLOVE: 34939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fxbhu4wktZ7B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"1107f97d-87c5-4b2b-96ab-619bbbc15f17","executionInfo":{"status":"error","timestamp":1587307404839,"user_tz":240,"elapsed":433,"user":{"displayName":"Alvin Li","photoUrl":"","userId":"06437038450383299514"}}},"source":[""],"execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-2263eb625fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnot_glove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'youre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'you are'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"theres\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"there is\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"whats\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"what is\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"theyre\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"they are\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 's' is not defined"]}]},{"cell_type":"code","metadata":{"id":"mbQo0e7vrVvE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e51ed412-1d8b-4b42-a8ac-c62906f779e6","executionInfo":{"status":"ok","timestamp":1587304347731,"user_tz":240,"elapsed":1865,"user":{"displayName":"Alvin Li","photoUrl":"","userId":"06437038450383299514"}}},"source":["from scipy.ndimage.interpolation import shift\n","inputs_1 = inputs\n","inputs_2 = outputs\n","outputs_1 = outputs\n","outputs_1 = shift(outputs_1, [0,-1], cval=0)\n","print(\"{},{}\".format(inputs_1.shape,outputs_1.shape))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(76543, 70),(76543, 70)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6MjpK66GrfpI","colab_type":"code","colab":{}},"source":["#https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, Dropout, TimeDistributed\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras.models import Model\n","latent_dim = 256\n","Shared_Embedding = Embedding(vocab_size,100,weights=[embedding_matrix],input_length=MAXLEN,trainable=True)\n","\n","encoder_inputs = Input(shape=(MAXLEN,), dtype='int32')\n","encoder_embedding = Shared_Embedding(encoder_inputs)\n","encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state = True)(encoder_embedding)\n","\n","decoder_inputs = Input(shape=(MAXLEN,), dtype='int32')\n","decoder_embedding = Shared_Embedding(decoder_inputs)\n","decoder_outputs, _, _ = LSTM(latent_dim, return_state=True, return_sequences=True)(decoder_embedding, initial_state=[state_h, state_c])\n","\n","outputs_model = Dense(1, activation='softmax')(decoder_outputs)\n","model = Model([encoder_inputs, decoder_inputs], outputs_model)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.05), metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-tcJb1Zri46","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7b588032-d36a-4113-87de-a6e6dca2cb29","executionInfo":{"status":"error","timestamp":1587307404239,"user_tz":240,"elapsed":2820061,"user":{"displayName":"Alvin Li","photoUrl":"","userId":"06437038450383299514"}}},"source":["hist = model.fit([inputs_1, inputs_2], outputs_1,batch_size=32,epochs=100,validation_split=0.2, verbose = 1)\n","model.save(\"2nd_m.h5\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1914/1914 [==============================] - 76s 40ms/step - loss: 386584.4062 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 2/100\n","1914/1914 [==============================] - 76s 40ms/step - loss: 386592.7812 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 3/100\n","1914/1914 [==============================] - 76s 40ms/step - loss: 386585.0938 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 4/100\n","1914/1914 [==============================] - 76s 40ms/step - loss: 386589.5000 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 5/100\n","1914/1914 [==============================] - 76s 40ms/step - loss: 386586.6562 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 6/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386601.4375 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 7/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386582.7500 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 8/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386584.4688 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 9/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386582.3750 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 10/100\n","1914/1914 [==============================] - 76s 40ms/step - loss: 386581.2188 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 11/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386584.8438 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 12/100\n","1914/1914 [==============================] - 76s 40ms/step - loss: 386584.1562 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 13/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386582.2500 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 14/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386591.3438 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 15/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386588.6875 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 16/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386585.2812 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 17/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386615.8125 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 18/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386580.2500 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 19/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386587.5000 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 20/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386585.8125 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 21/100\n","1914/1914 [==============================] - 79s 41ms/step - loss: 386596.6562 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 22/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386587.6875 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 23/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386584.0625 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 24/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386591.5625 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 25/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386596.8750 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 26/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386585.4688 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 27/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386584.7188 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 28/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386599.8125 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 29/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386586.4375 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 30/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386582.2812 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 31/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386576.2500 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 32/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386587.3750 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 33/100\n","1914/1914 [==============================] - 78s 41ms/step - loss: 386596.2500 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 34/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386594.9688 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 35/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386602.3750 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 36/100\n","1914/1914 [==============================] - 77s 40ms/step - loss: 386580.2500 - accuracy: 0.0065 - val_loss: 386322.4688 - val_accuracy: 0.0063\n","Epoch 37/100\n"," 839/1914 [============>.................] - ETA: 41s - loss: 387232.6250 - accuracy: 0.0065"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-dd15651c8f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2nd_m.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    850\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"IwBMGVqgtq2f","colab_type":"code","colab":{}},"source":["# use bidirectional lstm next time?\n","#https://github.com/oswaldoludwig/Adversarial-Learning-for-Generative-Conversational-Agents !!!!GAANNN!!!!\n","# Put attention in as well!\n","encoder_model = Model(encoder_inputs, [state_h, state_c])\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = LSTM(latent_dim, return_sequences=True, return_state=True)(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_hQCUjwytzPg","colab_type":"code","colab":{}},"source":["def decode_sequence(input_seq):\n","    input_seq = np.expand_dims(input_seq,axis=-1)\n","    states_value = encoder_model.predict(input_seq)\n","\n","    target_seq = np.zeros((1,1,1))\n","    target_seq[0, 0, 0] = vocab_size_y - 2\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = []\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        sampled_token_index = output_tokens[:,-1,:]\n","        decoded_sentence.append(sampled_token_index[0][0])\n","\n","        if (sampled_token_index == vocab_size_y - 1 or len(decoded_sentence) > MAXLEN):\n","            stop_condition = True\n","\n","        target_seq = np.zeros((1,1,1))\n","        target_seq[0,0,0] = sampled_token_index\n","        states_value = [h, c]\n","    pred = token_y.decode([int(i) for i in decoded_sentence])\n","    return pred\n","index_try = 33\n","input_seq = inputs_1[index_try: index_try + 1]\n","pred = decode_sequence(input_seq)\n","print('-')\n","print('Input sentence:', token_x.decode(np.squeeze(inputs_1[index_try], axis=-1)))\n","print('Decoded sentence:', pred)"],"execution_count":0,"outputs":[]}]}