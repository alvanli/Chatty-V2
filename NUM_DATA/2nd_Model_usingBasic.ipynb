{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2nd_Model_usingBasic",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqge7r5GOxX",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, I will use a separate dataset to ensure the model does in fact converge in other situations (because if trained on dw ds its not converging). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGqN2bd-GGK0",
        "colab_type": "code",
        "outputId": "d26e63fe-175a-4903-b70b-7d0afc4ff553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "%cd ..\n",
        "%cd root\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"basic_data.csv\")\n",
        "df.head()\n",
        "df.fillna('', inplace=True)\n",
        "print(len(df))\n",
        "x = df[\"x\"].tolist()\n",
        "y = df[\"y\"].tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/root\n",
            "50330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZX_oCBwXIOt",
        "colab_type": "code",
        "outputId": "09f326fb-9f8c-4fcf-d993-ed9a9282abf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_words = set()\n",
        "target_words = set()\n",
        "\n",
        "for line in x:\n",
        "    input_texts.append(str(line).split(\" \"))\n",
        "    for word in str(line).split(\" \"):\n",
        "        if word not in input_words:\n",
        "            input_words.add(word)\n",
        "\n",
        "for line in y:\n",
        "  target_texts.append(['\\t'] + str(line).split(\" \") + ['\\n'])\n",
        "  for word in str(line).split(\" \"):\n",
        "    if word not in target_words:\n",
        "        target_words.add(word)\n",
        "target_words.add(\"\\t\")\n",
        "target_words.add(\"\\n\")\n",
        "  \n",
        "input_words = sorted(list(input_words))\n",
        "target_words = sorted(list(target_words))\n",
        "num_encoder_tokens = len(input_words)\n",
        "num_decoder_tokens = len(target_words)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 50330\n",
            "Number of unique input tokens: 104\n",
            "Number of unique output tokens: 302\n",
            "Max sequence length for inputs: 3\n",
            "Max sequence length for outputs: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8-Cj-0iZJ0_",
        "colab_type": "code",
        "outputId": "2196f765-71d4-4f95-f9dd-2d57f483a66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "input_texts[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['23', 'plus', '56'],\n",
              " ['52', 'subtract', '22'],\n",
              " ['90', 'plus', '13'],\n",
              " ['23', 'add', '58'],\n",
              " ['78', 'subtract', '89']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro3ahxpDZPTT",
        "colab_type": "code",
        "outputId": "b5014f96-b408-4e80-db75-a39f9234c185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "target_texts[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['\\t', '79', '\\n'],\n",
              " ['\\t', '30', '\\n'],\n",
              " ['\\t', '103', '\\n'],\n",
              " ['\\t', '81', '\\n'],\n",
              " ['\\t', '-11', '\\n']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGG9MwD3aC6K",
        "colab_type": "code",
        "outputId": "994d1c51-c41d-4cf6-de4c-2d0137b04c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(target_words)])\n",
        "print(target_token_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\t': 0, '\\n': 1, '-1': 2, '-10': 3, '-11': 4, '-12': 5, '-13': 6, '-14': 7, '-15': 8, '-16': 9, '-17': 10, '-18': 11, '-19': 12, '-2': 13, '-20': 14, '-21': 15, '-22': 16, '-23': 17, '-24': 18, '-25': 19, '-26': 20, '-27': 21, '-28': 22, '-29': 23, '-3': 24, '-30': 25, '-31': 26, '-32': 27, '-33': 28, '-34': 29, '-35': 30, '-36': 31, '-37': 32, '-38': 33, '-39': 34, '-4': 35, '-40': 36, '-41': 37, '-42': 38, '-43': 39, '-44': 40, '-45': 41, '-46': 42, '-47': 43, '-48': 44, '-49': 45, '-5': 46, '-50': 47, '-51': 48, '-52': 49, '-53': 50, '-54': 51, '-55': 52, '-56': 53, '-57': 54, '-58': 55, '-59': 56, '-6': 57, '-60': 58, '-61': 59, '-62': 60, '-63': 61, '-64': 62, '-65': 63, '-66': 64, '-67': 65, '-68': 66, '-69': 67, '-7': 68, '-70': 69, '-71': 70, '-72': 71, '-73': 72, '-74': 73, '-75': 74, '-76': 75, '-77': 76, '-78': 77, '-79': 78, '-8': 79, '-80': 80, '-81': 81, '-82': 82, '-83': 83, '-84': 84, '-85': 85, '-86': 86, '-87': 87, '-88': 88, '-89': 89, '-9': 90, '-90': 91, '-91': 92, '-92': 93, '-93': 94, '-94': 95, '-95': 96, '-96': 97, '-97': 98, '-98': 99, '-99': 100, '0': 101, '1': 102, '10': 103, '100': 104, '101': 105, '102': 106, '103': 107, '104': 108, '105': 109, '106': 110, '107': 111, '108': 112, '109': 113, '11': 114, '110': 115, '111': 116, '112': 117, '113': 118, '114': 119, '115': 120, '116': 121, '117': 122, '118': 123, '119': 124, '12': 125, '120': 126, '121': 127, '122': 128, '123': 129, '124': 130, '125': 131, '126': 132, '127': 133, '128': 134, '129': 135, '13': 136, '130': 137, '131': 138, '132': 139, '133': 140, '134': 141, '135': 142, '136': 143, '137': 144, '138': 145, '139': 146, '14': 147, '140': 148, '141': 149, '142': 150, '143': 151, '144': 152, '145': 153, '146': 154, '147': 155, '148': 156, '149': 157, '15': 158, '150': 159, '151': 160, '152': 161, '153': 162, '154': 163, '155': 164, '156': 165, '157': 166, '158': 167, '159': 168, '16': 169, '160': 170, '161': 171, '162': 172, '163': 173, '164': 174, '165': 175, '166': 176, '167': 177, '168': 178, '169': 179, '17': 180, '170': 181, '171': 182, '172': 183, '173': 184, '174': 185, '175': 186, '176': 187, '177': 188, '178': 189, '179': 190, '18': 191, '180': 192, '181': 193, '182': 194, '183': 195, '184': 196, '185': 197, '186': 198, '187': 199, '188': 200, '189': 201, '19': 202, '190': 203, '191': 204, '192': 205, '193': 206, '194': 207, '195': 208, '196': 209, '197': 210, '198': 211, '199': 212, '2': 213, '20': 214, '200': 215, '21': 216, '22': 217, '23': 218, '24': 219, '25': 220, '26': 221, '27': 222, '28': 223, '29': 224, '3': 225, '30': 226, '31': 227, '32': 228, '33': 229, '34': 230, '35': 231, '36': 232, '37': 233, '38': 234, '39': 235, '4': 236, '40': 237, '41': 238, '42': 239, '43': 240, '44': 241, '45': 242, '46': 243, '47': 244, '48': 245, '49': 246, '5': 247, '50': 248, '51': 249, '52': 250, '53': 251, '54': 252, '55': 253, '56': 254, '57': 255, '58': 256, '59': 257, '6': 258, '60': 259, '61': 260, '62': 261, '63': 262, '64': 263, '65': 264, '66': 265, '67': 266, '68': 267, '69': 268, '7': 269, '70': 270, '71': 271, '72': 272, '73': 273, '74': 274, '75': 275, '76': 276, '77': 277, '78': 278, '79': 279, '8': 280, '80': 281, '81': 282, '82': 283, '83': 284, '84': 285, '85': 286, '86': 287, '87': 288, '88': 289, '89': 290, '9': 291, '90': 292, '91': 293, '92': 294, '93': 295, '94': 296, '95': 297, '96': 298, '97': 299, '98': 300, '99': 301}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_sxSPrBVLVw",
        "colab_type": "code",
        "outputId": "e75ea767-0f56-4bdc-df18-0e8cea186d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, word in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[word]] = 1.\n",
        "    for t, word in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[word]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "\n",
        "model.save('m2_simp.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40264 samples, validate on 10066 samples\n",
            "Epoch 1/100\n",
            "40264/40264 [==============================] - 11s 270us/step - loss: 1.6560 - accuracy: 0.3379 - val_loss: 1.4314 - val_accuracy: 0.3430\n",
            "Epoch 2/100\n",
            "40264/40264 [==============================] - 9s 212us/step - loss: 1.2860 - accuracy: 0.3506 - val_loss: 1.1986 - val_accuracy: 0.3504\n",
            "Epoch 3/100\n",
            "40264/40264 [==============================] - 9s 212us/step - loss: 1.0918 - accuracy: 0.3637 - val_loss: 1.0876 - val_accuracy: 0.3587\n",
            "Epoch 4/100\n",
            "40264/40264 [==============================] - 9s 212us/step - loss: 0.9727 - accuracy: 0.3752 - val_loss: 0.9277 - val_accuracy: 0.3852\n",
            "Epoch 5/100\n",
            "40264/40264 [==============================] - 8s 210us/step - loss: 0.8962 - accuracy: 0.3846 - val_loss: 0.9776 - val_accuracy: 0.3729\n",
            "Epoch 6/100\n",
            "40264/40264 [==============================] - 9s 224us/step - loss: 0.8424 - accuracy: 0.3916 - val_loss: 0.8378 - val_accuracy: 0.3914\n",
            "Epoch 7/100\n",
            "40264/40264 [==============================] - 9s 213us/step - loss: 0.7966 - accuracy: 0.3997 - val_loss: 0.7940 - val_accuracy: 0.3967\n",
            "Epoch 8/100\n",
            "40264/40264 [==============================] - 9s 212us/step - loss: 0.7572 - accuracy: 0.4061 - val_loss: 0.7615 - val_accuracy: 0.3979\n",
            "Epoch 9/100\n",
            "40264/40264 [==============================] - 9s 214us/step - loss: 0.7242 - accuracy: 0.4124 - val_loss: 0.8324 - val_accuracy: 0.3955\n",
            "Epoch 10/100\n",
            "40264/40264 [==============================] - 9s 214us/step - loss: 0.6961 - accuracy: 0.4182 - val_loss: 0.7383 - val_accuracy: 0.3982\n",
            "Epoch 11/100\n",
            "40264/40264 [==============================] - 9s 213us/step - loss: 0.6706 - accuracy: 0.4247 - val_loss: 0.7165 - val_accuracy: 0.4086\n",
            "Epoch 12/100\n",
            "40264/40264 [==============================] - 8s 208us/step - loss: 0.6511 - accuracy: 0.4292 - val_loss: 0.7567 - val_accuracy: 0.3920\n",
            "Epoch 13/100\n",
            "40264/40264 [==============================] - 9s 211us/step - loss: 0.6289 - accuracy: 0.4342 - val_loss: 0.6593 - val_accuracy: 0.4225\n",
            "Epoch 14/100\n",
            "40264/40264 [==============================] - 9s 214us/step - loss: 0.6112 - accuracy: 0.4398 - val_loss: 0.6626 - val_accuracy: 0.4115\n",
            "Epoch 15/100\n",
            "40264/40264 [==============================] - 8s 211us/step - loss: 0.5934 - accuracy: 0.4438 - val_loss: 0.6598 - val_accuracy: 0.4104\n",
            "Epoch 16/100\n",
            "40264/40264 [==============================] - 8s 208us/step - loss: 0.5758 - accuracy: 0.4505 - val_loss: 0.5918 - val_accuracy: 0.4330\n",
            "Epoch 17/100\n",
            "40264/40264 [==============================] - 8s 205us/step - loss: 0.5597 - accuracy: 0.4532 - val_loss: 0.6341 - val_accuracy: 0.4110\n",
            "Epoch 18/100\n",
            "40264/40264 [==============================] - 8s 204us/step - loss: 0.5454 - accuracy: 0.4573 - val_loss: 0.5738 - val_accuracy: 0.4407\n",
            "Epoch 19/100\n",
            "40264/40264 [==============================] - 8s 211us/step - loss: 0.5319 - accuracy: 0.4625 - val_loss: 0.6111 - val_accuracy: 0.4463\n",
            "Epoch 20/100\n",
            "40264/40264 [==============================] - 8s 206us/step - loss: 0.5200 - accuracy: 0.4666 - val_loss: 0.5912 - val_accuracy: 0.4367\n",
            "Epoch 21/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.5077 - accuracy: 0.4720 - val_loss: 0.5475 - val_accuracy: 0.4462\n",
            "Epoch 22/100\n",
            "40264/40264 [==============================] - 8s 208us/step - loss: 0.4954 - accuracy: 0.4746 - val_loss: 0.6070 - val_accuracy: 0.4242\n",
            "Epoch 23/100\n",
            "40264/40264 [==============================] - 8s 204us/step - loss: 0.4827 - accuracy: 0.4777 - val_loss: 0.5340 - val_accuracy: 0.4511\n",
            "Epoch 24/100\n",
            "40264/40264 [==============================] - 8s 204us/step - loss: 0.4729 - accuracy: 0.4823 - val_loss: 0.5662 - val_accuracy: 0.4522\n",
            "Epoch 25/100\n",
            "40264/40264 [==============================] - 8s 205us/step - loss: 0.4626 - accuracy: 0.4864 - val_loss: 0.4696 - val_accuracy: 0.4806\n",
            "Epoch 26/100\n",
            "40264/40264 [==============================] - 8s 206us/step - loss: 0.4517 - accuracy: 0.4904 - val_loss: 0.5105 - val_accuracy: 0.4742\n",
            "Epoch 27/100\n",
            "40264/40264 [==============================] - 8s 204us/step - loss: 0.4419 - accuracy: 0.4953 - val_loss: 0.4934 - val_accuracy: 0.4714\n",
            "Epoch 28/100\n",
            "40264/40264 [==============================] - 8s 205us/step - loss: 0.4329 - accuracy: 0.4972 - val_loss: 0.4422 - val_accuracy: 0.4912\n",
            "Epoch 29/100\n",
            "40264/40264 [==============================] - 8s 206us/step - loss: 0.4231 - accuracy: 0.5023 - val_loss: 0.5179 - val_accuracy: 0.4579\n",
            "Epoch 30/100\n",
            "40264/40264 [==============================] - 8s 208us/step - loss: 0.4144 - accuracy: 0.5036 - val_loss: 0.5279 - val_accuracy: 0.4398\n",
            "Epoch 31/100\n",
            "40264/40264 [==============================] - 8s 208us/step - loss: 0.4047 - accuracy: 0.5084 - val_loss: 0.4858 - val_accuracy: 0.4869\n",
            "Epoch 32/100\n",
            "40264/40264 [==============================] - 8s 204us/step - loss: 0.3976 - accuracy: 0.5119 - val_loss: 0.4448 - val_accuracy: 0.4823\n",
            "Epoch 33/100\n",
            "40264/40264 [==============================] - 8s 203us/step - loss: 0.3893 - accuracy: 0.5151 - val_loss: 0.3993 - val_accuracy: 0.5072\n",
            "Epoch 34/100\n",
            "40264/40264 [==============================] - 8s 208us/step - loss: 0.3815 - accuracy: 0.5196 - val_loss: 0.4618 - val_accuracy: 0.4760\n",
            "Epoch 35/100\n",
            "40264/40264 [==============================] - 8s 201us/step - loss: 0.3742 - accuracy: 0.5230 - val_loss: 0.4561 - val_accuracy: 0.4650\n",
            "Epoch 36/100\n",
            "40264/40264 [==============================] - 8s 209us/step - loss: 0.3671 - accuracy: 0.5251 - val_loss: 0.4396 - val_accuracy: 0.4856\n",
            "Epoch 37/100\n",
            "40264/40264 [==============================] - 8s 203us/step - loss: 0.3605 - accuracy: 0.5280 - val_loss: 0.4409 - val_accuracy: 0.4848\n",
            "Epoch 38/100\n",
            "40264/40264 [==============================] - 8s 200us/step - loss: 0.3545 - accuracy: 0.5302 - val_loss: 0.3808 - val_accuracy: 0.5112\n",
            "Epoch 39/100\n",
            "40264/40264 [==============================] - 8s 200us/step - loss: 0.3473 - accuracy: 0.5326 - val_loss: 0.3791 - val_accuracy: 0.5133\n",
            "Epoch 40/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.3397 - accuracy: 0.5372 - val_loss: 0.3619 - val_accuracy: 0.5210\n",
            "Epoch 41/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.3342 - accuracy: 0.5402 - val_loss: 0.4332 - val_accuracy: 0.4842\n",
            "Epoch 42/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.3282 - accuracy: 0.5419 - val_loss: 0.4185 - val_accuracy: 0.4838\n",
            "Epoch 43/100\n",
            "40264/40264 [==============================] - 8s 208us/step - loss: 0.3226 - accuracy: 0.5445 - val_loss: 0.4474 - val_accuracy: 0.4959\n",
            "Epoch 44/100\n",
            "40264/40264 [==============================] - 8s 207us/step - loss: 0.3169 - accuracy: 0.5474 - val_loss: 0.3962 - val_accuracy: 0.4997\n",
            "Epoch 45/100\n",
            "40264/40264 [==============================] - 8s 199us/step - loss: 0.3104 - accuracy: 0.5506 - val_loss: 0.3740 - val_accuracy: 0.5200\n",
            "Epoch 46/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.3053 - accuracy: 0.5521 - val_loss: 0.3165 - val_accuracy: 0.5472\n",
            "Epoch 47/100\n",
            "40264/40264 [==============================] - 8s 199us/step - loss: 0.2998 - accuracy: 0.5556 - val_loss: 0.4583 - val_accuracy: 0.4808\n",
            "Epoch 48/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.2935 - accuracy: 0.5582 - val_loss: 0.3423 - val_accuracy: 0.5346\n",
            "Epoch 49/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.2891 - accuracy: 0.5594 - val_loss: 0.3766 - val_accuracy: 0.5057\n",
            "Epoch 50/100\n",
            "40264/40264 [==============================] - 8s 200us/step - loss: 0.2843 - accuracy: 0.5616 - val_loss: 0.4079 - val_accuracy: 0.5015\n",
            "Epoch 51/100\n",
            "40264/40264 [==============================] - 9s 211us/step - loss: 0.2788 - accuracy: 0.5642 - val_loss: 0.3130 - val_accuracy: 0.5429\n",
            "Epoch 52/100\n",
            "40264/40264 [==============================] - 8s 200us/step - loss: 0.2733 - accuracy: 0.5664 - val_loss: 0.3247 - val_accuracy: 0.5360\n",
            "Epoch 53/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.2679 - accuracy: 0.5686 - val_loss: 0.3241 - val_accuracy: 0.5420\n",
            "Epoch 54/100\n",
            "40264/40264 [==============================] - 8s 201us/step - loss: 0.2639 - accuracy: 0.5707 - val_loss: 0.2994 - val_accuracy: 0.5489\n",
            "Epoch 55/100\n",
            "40264/40264 [==============================] - 8s 197us/step - loss: 0.2590 - accuracy: 0.5726 - val_loss: 0.3658 - val_accuracy: 0.5151\n",
            "Epoch 56/100\n",
            "40264/40264 [==============================] - 8s 195us/step - loss: 0.2541 - accuracy: 0.5749 - val_loss: 0.4179 - val_accuracy: 0.4945\n",
            "Epoch 57/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.2495 - accuracy: 0.5775 - val_loss: 0.3425 - val_accuracy: 0.5247\n",
            "Epoch 58/100\n",
            "40264/40264 [==============================] - 8s 201us/step - loss: 0.2449 - accuracy: 0.5778 - val_loss: 0.4014 - val_accuracy: 0.5110\n",
            "Epoch 59/100\n",
            "40264/40264 [==============================] - 8s 203us/step - loss: 0.2391 - accuracy: 0.5827 - val_loss: 0.3929 - val_accuracy: 0.5134\n",
            "Epoch 60/100\n",
            "40264/40264 [==============================] - 8s 205us/step - loss: 0.2362 - accuracy: 0.5814 - val_loss: 0.4001 - val_accuracy: 0.4973\n",
            "Epoch 61/100\n",
            "40264/40264 [==============================] - 8s 208us/step - loss: 0.2321 - accuracy: 0.5840 - val_loss: 0.3087 - val_accuracy: 0.5388\n",
            "Epoch 62/100\n",
            "40264/40264 [==============================] - 8s 201us/step - loss: 0.2280 - accuracy: 0.5860 - val_loss: 0.3186 - val_accuracy: 0.5379\n",
            "Epoch 63/100\n",
            "40264/40264 [==============================] - 8s 204us/step - loss: 0.2243 - accuracy: 0.5874 - val_loss: 0.3115 - val_accuracy: 0.5424\n",
            "Epoch 64/100\n",
            "40264/40264 [==============================] - 8s 202us/step - loss: 0.2217 - accuracy: 0.5882 - val_loss: 0.3235 - val_accuracy: 0.5336\n",
            "Epoch 65/100\n",
            "40264/40264 [==============================] - 8s 203us/step - loss: 0.2177 - accuracy: 0.5907 - val_loss: 0.3221 - val_accuracy: 0.5323\n",
            "Epoch 66/100\n",
            "40264/40264 [==============================] - 8s 201us/step - loss: 0.2138 - accuracy: 0.5925 - val_loss: 0.3463 - val_accuracy: 0.5277\n",
            "Epoch 67/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.2111 - accuracy: 0.5928 - val_loss: 0.3383 - val_accuracy: 0.5274\n",
            "Epoch 68/100\n",
            "40264/40264 [==============================] - 8s 200us/step - loss: 0.2064 - accuracy: 0.5953 - val_loss: 0.3352 - val_accuracy: 0.5312\n",
            "Epoch 69/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.2031 - accuracy: 0.5966 - val_loss: 0.2714 - val_accuracy: 0.5615\n",
            "Epoch 70/100\n",
            "40264/40264 [==============================] - 8s 196us/step - loss: 0.2004 - accuracy: 0.5971 - val_loss: 0.2633 - val_accuracy: 0.5612\n",
            "Epoch 71/100\n",
            "40264/40264 [==============================] - 8s 196us/step - loss: 0.1970 - accuracy: 0.5993 - val_loss: 0.2328 - val_accuracy: 0.5790\n",
            "Epoch 72/100\n",
            "40264/40264 [==============================] - 8s 193us/step - loss: 0.1928 - accuracy: 0.6014 - val_loss: 0.3688 - val_accuracy: 0.5376\n",
            "Epoch 73/100\n",
            "40264/40264 [==============================] - 8s 195us/step - loss: 0.1902 - accuracy: 0.6023 - val_loss: 0.3039 - val_accuracy: 0.5432\n",
            "Epoch 74/100\n",
            "40264/40264 [==============================] - 8s 193us/step - loss: 0.1865 - accuracy: 0.6031 - val_loss: 0.3278 - val_accuracy: 0.5519\n",
            "Epoch 75/100\n",
            "40264/40264 [==============================] - 8s 196us/step - loss: 0.1846 - accuracy: 0.6043 - val_loss: 0.2616 - val_accuracy: 0.5632\n",
            "Epoch 76/100\n",
            "40264/40264 [==============================] - 8s 197us/step - loss: 0.1810 - accuracy: 0.6046 - val_loss: 0.2611 - val_accuracy: 0.5696\n",
            "Epoch 77/100\n",
            "40264/40264 [==============================] - 8s 195us/step - loss: 0.1790 - accuracy: 0.6059 - val_loss: 0.3798 - val_accuracy: 0.5293\n",
            "Epoch 78/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.1753 - accuracy: 0.6079 - val_loss: 0.2957 - val_accuracy: 0.5456\n",
            "Epoch 79/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.1721 - accuracy: 0.6088 - val_loss: 0.3580 - val_accuracy: 0.5270\n",
            "Epoch 80/100\n",
            "40264/40264 [==============================] - 8s 193us/step - loss: 0.1692 - accuracy: 0.6103 - val_loss: 0.2394 - val_accuracy: 0.5759\n",
            "Epoch 81/100\n",
            "40264/40264 [==============================] - 8s 199us/step - loss: 0.1662 - accuracy: 0.6110 - val_loss: 0.3018 - val_accuracy: 0.5530\n",
            "Epoch 82/100\n",
            "40264/40264 [==============================] - 8s 206us/step - loss: 0.1637 - accuracy: 0.6117 - val_loss: 0.3159 - val_accuracy: 0.5535\n",
            "Epoch 83/100\n",
            "40264/40264 [==============================] - 8s 195us/step - loss: 0.1604 - accuracy: 0.6136 - val_loss: 0.3081 - val_accuracy: 0.5548\n",
            "Epoch 84/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.1564 - accuracy: 0.6145 - val_loss: 0.2989 - val_accuracy: 0.5579\n",
            "Epoch 85/100\n",
            "40264/40264 [==============================] - 8s 196us/step - loss: 0.1543 - accuracy: 0.6154 - val_loss: 0.1997 - val_accuracy: 0.5926\n",
            "Epoch 86/100\n",
            "40264/40264 [==============================] - 8s 194us/step - loss: 0.1514 - accuracy: 0.6167 - val_loss: 0.3412 - val_accuracy: 0.5287\n",
            "Epoch 87/100\n",
            "40264/40264 [==============================] - 8s 192us/step - loss: 0.1490 - accuracy: 0.6177 - val_loss: 0.2870 - val_accuracy: 0.5559\n",
            "Epoch 88/100\n",
            "40264/40264 [==============================] - 8s 194us/step - loss: 0.1465 - accuracy: 0.6187 - val_loss: 0.3015 - val_accuracy: 0.5568\n",
            "Epoch 89/100\n",
            "40264/40264 [==============================] - 8s 199us/step - loss: 0.1442 - accuracy: 0.6193 - val_loss: 0.2520 - val_accuracy: 0.5712\n",
            "Epoch 90/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.1428 - accuracy: 0.6206 - val_loss: 0.2341 - val_accuracy: 0.5810\n",
            "Epoch 91/100\n",
            "40264/40264 [==============================] - 8s 194us/step - loss: 0.1398 - accuracy: 0.6208 - val_loss: 0.2338 - val_accuracy: 0.5739\n",
            "Epoch 92/100\n",
            "40264/40264 [==============================] - 8s 195us/step - loss: 0.1380 - accuracy: 0.6217 - val_loss: 0.2124 - val_accuracy: 0.5898\n",
            "Epoch 93/100\n",
            "40264/40264 [==============================] - 8s 195us/step - loss: 0.1363 - accuracy: 0.6219 - val_loss: 0.1877 - val_accuracy: 0.5979\n",
            "Epoch 94/100\n",
            "40264/40264 [==============================] - 8s 196us/step - loss: 0.1326 - accuracy: 0.6238 - val_loss: 0.2604 - val_accuracy: 0.5702\n",
            "Epoch 95/100\n",
            "40264/40264 [==============================] - 8s 197us/step - loss: 0.1319 - accuracy: 0.6236 - val_loss: 0.3004 - val_accuracy: 0.5676\n",
            "Epoch 96/100\n",
            "40264/40264 [==============================] - 8s 197us/step - loss: 0.1301 - accuracy: 0.6246 - val_loss: 0.2055 - val_accuracy: 0.5881\n",
            "Epoch 97/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.1268 - accuracy: 0.6259 - val_loss: 0.2668 - val_accuracy: 0.5654\n",
            "Epoch 98/100\n",
            "40264/40264 [==============================] - 8s 196us/step - loss: 0.1259 - accuracy: 0.6261 - val_loss: 0.2458 - val_accuracy: 0.5712\n",
            "Epoch 99/100\n",
            "40264/40264 [==============================] - 8s 198us/step - loss: 0.1231 - accuracy: 0.6271 - val_loss: 0.2334 - val_accuracy: 0.5773\n",
            "Epoch 100/100\n",
            "40264/40264 [==============================] - 8s 196us/step - loss: 0.1207 - accuracy: 0.6280 - val_loss: 0.2039 - val_accuracy: 0.5904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13jYFeFoWT0Z",
        "colab_type": "code",
        "outputId": "47dfd171-93af-4b8e-9098-c92af5dc3fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: ['23', 'plus', '56']\n",
            "Decoded sentence: 79\n",
            "\n",
            "-\n",
            "Input sentence: ['52', 'subtract', '22']\n",
            "Decoded sentence: 30\n",
            "\n",
            "-\n",
            "Input sentence: ['90', 'plus', '13']\n",
            "Decoded sentence: 103\n",
            "\n",
            "-\n",
            "Input sentence: ['23', 'add', '58']\n",
            "Decoded sentence: 81\n",
            "\n",
            "-\n",
            "Input sentence: ['78', 'subtract', '89']\n",
            "Decoded sentence: -11\n",
            "\n",
            "-\n",
            "Input sentence: ['89', 'subtract', '61']\n",
            "Decoded sentence: 28\n",
            "\n",
            "-\n",
            "Input sentence: ['39', 'subtract', '9']\n",
            "Decoded sentence: 30\n",
            "\n",
            "-\n",
            "Input sentence: ['31', 'plus', '80']\n",
            "Decoded sentence: 111\n",
            "\n",
            "-\n",
            "Input sentence: ['73', 'plus', '30']\n",
            "Decoded sentence: 103\n",
            "\n",
            "-\n",
            "Input sentence: ['24', 'subtract', '42']\n",
            "Decoded sentence: -18\n",
            "\n",
            "-\n",
            "Input sentence: ['14', 'add', '49']\n",
            "Decoded sentence: 63\n",
            "\n",
            "-\n",
            "Input sentence: ['72', 'add', '3']\n",
            "Decoded sentence: 75\n",
            "\n",
            "-\n",
            "Input sentence: ['95', 'subtract', '78']\n",
            "Decoded sentence: 17\n",
            "\n",
            "-\n",
            "Input sentence: ['87', 'plus', '16']\n",
            "Decoded sentence: 103\n",
            "\n",
            "-\n",
            "Input sentence: ['31', 'add', '17']\n",
            "Decoded sentence: 48\n",
            "\n",
            "-\n",
            "Input sentence: ['12', 'plus', '1']\n",
            "Decoded sentence: 13\n",
            "\n",
            "-\n",
            "Input sentence: ['91', 'add', '7']\n",
            "Decoded sentence: 98\n",
            "\n",
            "-\n",
            "Input sentence: ['89', 'subtract', '28']\n",
            "Decoded sentence: 60\n",
            "\n",
            "-\n",
            "Input sentence: ['94', 'subtract', '85']\n",
            "Decoded sentence: 9\n",
            "\n",
            "-\n",
            "Input sentence: ['93', 'plus', '24']\n",
            "Decoded sentence: 117\n",
            "\n",
            "-\n",
            "Input sentence: ['29', 'add', '6']\n",
            "Decoded sentence: 35\n",
            "\n",
            "-\n",
            "Input sentence: ['11', 'plus', '11']\n",
            "Decoded sentence: 22\n",
            "\n",
            "-\n",
            "Input sentence: ['75', 'minus', '35']\n",
            "Decoded sentence: 40\n",
            "\n",
            "-\n",
            "Input sentence: ['35', 'plus', '32']\n",
            "Decoded sentence: 67\n",
            "\n",
            "-\n",
            "Input sentence: ['15', 'minus', '63']\n",
            "Decoded sentence: -48\n",
            "\n",
            "-\n",
            "Input sentence: ['11', 'add', '88']\n",
            "Decoded sentence: 99\n",
            "\n",
            "-\n",
            "Input sentence: ['5', 'subtract', '87']\n",
            "Decoded sentence: -82\n",
            "\n",
            "-\n",
            "Input sentence: ['44', 'minus', '35']\n",
            "Decoded sentence: 9\n",
            "\n",
            "-\n",
            "Input sentence: ['2', 'subtract', '71']\n",
            "Decoded sentence: -69\n",
            "\n",
            "-\n",
            "Input sentence: ['89', 'add', '54']\n",
            "Decoded sentence: 144\n",
            "\n",
            "-\n",
            "Input sentence: ['29', 'subtract', '78']\n",
            "Decoded sentence: -49\n",
            "\n",
            "-\n",
            "Input sentence: ['67', 'subtract', '8']\n",
            "Decoded sentence: 59\n",
            "\n",
            "-\n",
            "Input sentence: ['37', 'plus', '71']\n",
            "Decoded sentence: 108\n",
            "\n",
            "-\n",
            "Input sentence: ['92', 'add', '53']\n",
            "Decoded sentence: 145\n",
            "\n",
            "-\n",
            "Input sentence: ['91', 'subtract', '39']\n",
            "Decoded sentence: 52\n",
            "\n",
            "-\n",
            "Input sentence: ['64', 'minus', '9']\n",
            "Decoded sentence: 55\n",
            "\n",
            "-\n",
            "Input sentence: ['56', 'subtract', '43']\n",
            "Decoded sentence: 13\n",
            "\n",
            "-\n",
            "Input sentence: ['1', 'minus', '98']\n",
            "Decoded sentence: -96\n",
            "\n",
            "-\n",
            "Input sentence: ['59', 'subtract', '34']\n",
            "Decoded sentence: 25\n",
            "\n",
            "-\n",
            "Input sentence: ['51', 'subtract', '61']\n",
            "Decoded sentence: -10\n",
            "\n",
            "-\n",
            "Input sentence: ['100', 'add', '19']\n",
            "Decoded sentence: 120\n",
            "\n",
            "-\n",
            "Input sentence: ['61', 'minus', '19']\n",
            "Decoded sentence: 42\n",
            "\n",
            "-\n",
            "Input sentence: ['1', 'plus', '97']\n",
            "Decoded sentence: 98\n",
            "\n",
            "-\n",
            "Input sentence: ['19', 'add', '82']\n",
            "Decoded sentence: 101\n",
            "\n",
            "-\n",
            "Input sentence: ['53', 'add', '19']\n",
            "Decoded sentence: 72\n",
            "\n",
            "-\n",
            "Input sentence: ['81', 'plus', '89']\n",
            "Decoded sentence: 170\n",
            "\n",
            "-\n",
            "Input sentence: ['34', 'plus', '48']\n",
            "Decoded sentence: 82\n",
            "\n",
            "-\n",
            "Input sentence: ['58', 'subtract', '49']\n",
            "Decoded sentence: 9\n",
            "\n",
            "-\n",
            "Input sentence: ['41', 'subtract', '49']\n",
            "Decoded sentence: -8\n",
            "\n",
            "-\n",
            "Input sentence: ['87', 'subtract', '60']\n",
            "Decoded sentence: 27\n",
            "\n",
            "-\n",
            "Input sentence: ['30', 'minus', '32']\n",
            "Decoded sentence: -2\n",
            "\n",
            "-\n",
            "Input sentence: ['67', 'add', '7']\n",
            "Decoded sentence: 74\n",
            "\n",
            "-\n",
            "Input sentence: ['8', 'subtract', '58']\n",
            "Decoded sentence: -50\n",
            "\n",
            "-\n",
            "Input sentence: ['44', 'subtract', '54']\n",
            "Decoded sentence: -10\n",
            "\n",
            "-\n",
            "Input sentence: ['28', 'minus', '65']\n",
            "Decoded sentence: -37\n",
            "\n",
            "-\n",
            "Input sentence: ['58', 'plus', '43']\n",
            "Decoded sentence: 101\n",
            "\n",
            "-\n",
            "Input sentence: ['71', 'add', '92']\n",
            "Decoded sentence: 163\n",
            "\n",
            "-\n",
            "Input sentence: ['72', 'plus', '62']\n",
            "Decoded sentence: 134\n",
            "\n",
            "-\n",
            "Input sentence: ['4', 'subtract', '44']\n",
            "Decoded sentence: -40\n",
            "\n",
            "-\n",
            "Input sentence: ['68', 'add', '48']\n",
            "Decoded sentence: 116\n",
            "\n",
            "-\n",
            "Input sentence: ['82', 'subtract', '3']\n",
            "Decoded sentence: 79\n",
            "\n",
            "-\n",
            "Input sentence: ['39', 'minus', '76']\n",
            "Decoded sentence: -37\n",
            "\n",
            "-\n",
            "Input sentence: ['92', 'minus', '12']\n",
            "Decoded sentence: 80\n",
            "\n",
            "-\n",
            "Input sentence: ['51', 'minus', '64']\n",
            "Decoded sentence: -13\n",
            "\n",
            "-\n",
            "Input sentence: ['31', 'minus', '65']\n",
            "Decoded sentence: -34\n",
            "\n",
            "-\n",
            "Input sentence: ['49', 'minus', '30']\n",
            "Decoded sentence: 19\n",
            "\n",
            "-\n",
            "Input sentence: ['93', 'add', '80']\n",
            "Decoded sentence: 173\n",
            "\n",
            "-\n",
            "Input sentence: ['15', 'subtract', '55']\n",
            "Decoded sentence: -39\n",
            "\n",
            "-\n",
            "Input sentence: ['92', 'subtract', '58']\n",
            "Decoded sentence: 34\n",
            "\n",
            "-\n",
            "Input sentence: ['2', 'subtract', '2']\n",
            "Decoded sentence: -1\n",
            "\n",
            "-\n",
            "Input sentence: ['54', 'add', '8']\n",
            "Decoded sentence: 63\n",
            "\n",
            "-\n",
            "Input sentence: ['9', 'plus', '43']\n",
            "Decoded sentence: 52\n",
            "\n",
            "-\n",
            "Input sentence: ['24', 'add', '81']\n",
            "Decoded sentence: 105\n",
            "\n",
            "-\n",
            "Input sentence: ['5', 'plus', '36']\n",
            "Decoded sentence: 42\n",
            "\n",
            "-\n",
            "Input sentence: ['64', 'add', '63']\n",
            "Decoded sentence: 127\n",
            "\n",
            "-\n",
            "Input sentence: ['68', 'minus', '74']\n",
            "Decoded sentence: -6\n",
            "\n",
            "-\n",
            "Input sentence: ['25', 'add', '22']\n",
            "Decoded sentence: 47\n",
            "\n",
            "-\n",
            "Input sentence: ['100', 'minus', '86']\n",
            "Decoded sentence: 14\n",
            "\n",
            "-\n",
            "Input sentence: ['81', 'minus', '23']\n",
            "Decoded sentence: 58\n",
            "\n",
            "-\n",
            "Input sentence: ['49', 'plus', '25']\n",
            "Decoded sentence: 74\n",
            "\n",
            "-\n",
            "Input sentence: ['24', 'minus', '25']\n",
            "Decoded sentence: -1\n",
            "\n",
            "-\n",
            "Input sentence: ['54', 'minus', '11']\n",
            "Decoded sentence: 43\n",
            "\n",
            "-\n",
            "Input sentence: ['83', 'add', '28']\n",
            "Decoded sentence: 111\n",
            "\n",
            "-\n",
            "Input sentence: ['93', 'add', '78']\n",
            "Decoded sentence: 171\n",
            "\n",
            "-\n",
            "Input sentence: ['61', 'plus', '29']\n",
            "Decoded sentence: 90\n",
            "\n",
            "-\n",
            "Input sentence: ['46', 'plus', '47']\n",
            "Decoded sentence: 93\n",
            "\n",
            "-\n",
            "Input sentence: ['39', 'minus', '67']\n",
            "Decoded sentence: -28\n",
            "\n",
            "-\n",
            "Input sentence: ['17', 'add', '66']\n",
            "Decoded sentence: 83\n",
            "\n",
            "-\n",
            "Input sentence: ['37', 'minus', '71']\n",
            "Decoded sentence: -34\n",
            "\n",
            "-\n",
            "Input sentence: ['36', 'plus', '69']\n",
            "Decoded sentence: 105\n",
            "\n",
            "-\n",
            "Input sentence: ['65', 'minus', '75']\n",
            "Decoded sentence: -10\n",
            "\n",
            "-\n",
            "Input sentence: ['62', 'plus', '25']\n",
            "Decoded sentence: 86\n",
            "\n",
            "-\n",
            "Input sentence: ['68', 'subtract', '39']\n",
            "Decoded sentence: 29\n",
            "\n",
            "-\n",
            "Input sentence: ['47', 'add', '9']\n",
            "Decoded sentence: 56\n",
            "\n",
            "-\n",
            "Input sentence: ['19', 'minus', '92']\n",
            "Decoded sentence: -73\n",
            "\n",
            "-\n",
            "Input sentence: ['91', 'plus', '5']\n",
            "Decoded sentence: 96\n",
            "\n",
            "-\n",
            "Input sentence: ['47', 'add', '54']\n",
            "Decoded sentence: 101\n",
            "\n",
            "-\n",
            "Input sentence: ['57', 'subtract', '6']\n",
            "Decoded sentence: 51\n",
            "\n",
            "-\n",
            "Input sentence: ['94', 'add', '17']\n",
            "Decoded sentence: 111\n",
            "\n",
            "-\n",
            "Input sentence: ['99', 'add', '49']\n",
            "Decoded sentence: 149\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}